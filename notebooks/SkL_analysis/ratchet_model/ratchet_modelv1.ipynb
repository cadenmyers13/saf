{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: This will run if you have the the movies saved as \"start_numor\".npz files. Check other notebook titled SANS_to_npz.ipynb for code to assist in doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.signal import argrelextrema\n",
    "from ipywidgets import interact, IntSlider\n",
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_movies = {\n",
    "    # field sweeps\n",
    "    '55.3 K 50 mW Negative Field Sweep': ['54261', '54863', '55162', '55461', '55760', '56059', '56358'],\n",
    "    '55.3 K 50 mW Positive Field Sweep': ['73131', '73430', '73729', '74028', '74327', '74626'],\n",
    "    '55.8 K 25 mW Negative Field Sweep': ['68463', '68762', '69061', '69360', '69659', '69958'],\n",
    "    '55.8 K 25 mW Positive Field Sweep': ['70797', '71096', '71395', '71694', '71993', '72292'],\n",
    "\n",
    "    # temperature sweeps (only including those with signal)\n",
    "    '-29 mT 10 mW Temp Sweep': ['61221', '61759', '62417'],\n",
    "    '-29 mT 25 mW Temp Sweep': ['64690', '64152', '63614', '63076'],\n",
    "    '+29 mT 25 mW Temp Sweep': ['76899', '76361', '75823', '75285'],\n",
    "    '-29 mT 50 mW Temp Sweep': ['52666', '59887', '52128', '59349', '51590', '58811', '51052', '58273', '50514', '57735', '49976', '57197', '49438'],\n",
    "    '+29 mT 50 mW Temp Sweep': ['47963', '47425', '67624', '46887', '67086', '46349', '45811', '66670', '45268', '44730', '44192']\n",
    "}\n",
    "# bad data\n",
    "# '-29 mT 25 mW Temp Sweep': 65766, 65228, 66304\n",
    "\n",
    "\n",
    "# Movie numor matched with each title\n",
    "movie_to_title = {\n",
    "    # --- Field Sweeps ---\n",
    "    \n",
    "    # 55.3 K 50 mW Negative Field Sweep\n",
    "    '54261': '54261 55.3 K -23 mT 50 mW',\n",
    "    '54863': '54863 55.3 K -25 mT 50 mW',\n",
    "    '55162': '55162 55.3 K -27 mT 50 mW',\n",
    "    '55461': '55461 55.3 K -29 mT 50 mW',\n",
    "    '55760': '55760 55.3 K -31 mT 50 mW',\n",
    "    '56059': '56059 55.3 K -33 mT 50 mW',\n",
    "    '56358': '56358 55.3 K -35 mT 50 mW',\n",
    "\n",
    "    # 55.3 K 50 mW Positive Field Sweep\n",
    "    '73131': '73131 55.3 K +23 mT 50 mW',\n",
    "    '73430': '73430 55.3 K +25 mT 50 mW',\n",
    "    '73729': '73729 55.3 K +27 mT 50 mW',\n",
    "    '74028': '74028 55.3 K +29 mT 50 mW',\n",
    "    '74327': '74327 55.3 K +31 mT 50 mW',\n",
    "    '74626': '74626 55.3 K +33 mT 50 mW',\n",
    "\n",
    "    # 55.8 K 25 mW Negative Field Sweep\n",
    "    '68463': '68463 55.8 K -23 mT 25 mW',\n",
    "    '68762': '68762 55.8 K -25 mT 25 mW',\n",
    "    '69061': '69061 55.8 K -27 mT 25 mW',\n",
    "    '69360': '69360 55.8 K -29 mT 25 mW',\n",
    "    '69659': '69659 55.8 K -31 mT 25 mW',\n",
    "    '69958': '69958 55.8 K -33 mT 25 mW',\n",
    "\n",
    "    # 55.8 K 25 mW Positive Field Sweep\n",
    "    '70797': '70797 55.8 K +23 mT 25 mW',\n",
    "    '71096': '71096 55.8 K +25 mT 25 mW',\n",
    "    '71395': '71395 55.8 K +27 mT 25 mW',\n",
    "    '71694': '71694 55.8 K +29 mT 25 mW',\n",
    "    '71993': '71993 55.8 K +31 mT 25 mW',\n",
    "    '72292': '72292 55.8 K +33 mT 25 mW',\n",
    "\n",
    "    # --- Temperature Sweeps ---\n",
    "\n",
    "    # -29 mT 10 mW Temp Sweep\n",
    "    '61221': '61221 56.0 K -29 mT 10 mW',\n",
    "    '61759': '61759 56.3 K -29 mT 10 mW',\n",
    "    '62417': '62417 57.5 K -29 mT 10 mW',\n",
    "\n",
    "    # -29 mT 25 mW Temp Sweep\n",
    "    '65766': '65766 54.8 K -29 mT 25 mW',\n",
    "    '65228': '65228 55.3 K -29 mT 25 mW',\n",
    "    '64690': '64690 55.8 K -29 mT 25 mW',\n",
    "    '64152': '64152 56.3 K -29 mT 25 mW',\n",
    "    '63614': '63614 56.8 K -29 mT 25 mW',\n",
    "    '63076': '63076 57.3 K -29 mT 25 mW',\n",
    "\n",
    "    # +29 mT 25 mW Temp Sweep\n",
    "    '76899': '76899 55.8 K +29 mT 25 mW',\n",
    "    '76361': '76361 56.3 K +29 mT 25 mW',\n",
    "    '75823': '75823 56.8 K +29 mT 25 mW',\n",
    "    '75285': '75285 57.3 K +29 mT 25 mW',\n",
    "\n",
    "    # -29 mT 50 mW Temp Sweep\n",
    "    '52666': '52666 54.3 K -29 mT 50 mW',\n",
    "    '59887': '59887 54.5 K -29 mT 50 mW',\n",
    "    '52128': '52128 54.8 K -29 mT 50 mW',\n",
    "    '59349': '59349 55.0 K -29 mT 50 mW',\n",
    "    '51590': '51590 55.3 K -29 mT 50 mW',\n",
    "    '58811': '58811 55.5 K -29 mT 50 mW',\n",
    "    '51052': '51052 55.8 K -29 mT 50 mW',\n",
    "    '58273': '58273 56.0 K -29 mT 50 mW',\n",
    "    '50514': '50514 56.3 K -29 mT 50 mW',\n",
    "    '57735': '57735 56.5 K -29 mT 50 mW',\n",
    "    '49976': '49976 56.8 K -29 mT 50 mW',\n",
    "    '57197': '57197 57.0 K -29 mT 50 mW',\n",
    "    '49438': '49438 57.3 K -29 mT 50 mW',\n",
    "\n",
    "    # +29 mT 50 mW Temp Sweep\n",
    "    '47963': '47963 53.8 K +29 mT 50 mW',\n",
    "    '47425': '47425 54.3 K +29 mT 50 mW',\n",
    "    '67624': '67624 54.5 K +29 mT 50 mW',\n",
    "    '46887': '46887 54.8 K +29 mT 50 mW',\n",
    "    '67086': '67086 55.0 K +29 mT 50 mW',\n",
    "    '46349': '46349 55.3 K +29 mT 50 mW',\n",
    "    '45811': '45811 55.8 K +29 mT 50 mW',\n",
    "    '66670': '66670 55.9 K +29 mT 50 mW',\n",
    "    '45268': '45268 56.3 K +29 mT 50 mW',\n",
    "    '44730': '44730 56.8 K +29 mT 50 mW',\n",
    "    '44192': '44192 57.3 K +29 mT 50 mW',\n",
    "}\n",
    "[46349, 69958, 56059]\n",
    "filtered_indices = {\n",
    "    # --- Field Sweeps ---\n",
    "    \n",
    "    # 55.3 K 50 mW Negative Field Sweep\n",
    "    '54261': [],\n",
    "    '54863': [], \n",
    "    '55162': [], \n",
    "    '55461': [15, 16],\n",
    "    '55760': [], \n",
    "    '56059': [], \n",
    "    '56358': [],\n",
    "\n",
    "    # 55.3 K 50 mW Positive Field Sweep\n",
    "    '73131': [7], \n",
    "    '73430': [], \n",
    "    '73729': [], \n",
    "    '74028': [], \n",
    "    '74327': [129, 130, 214, 215], \n",
    "    '74626': [],\n",
    "\n",
    "    # 55.8 K 25 mW Negative Field Sweep\n",
    "    '68463': [265, 266],\n",
    "    '68762': [39, 40, 175, 176, 206],\n",
    "    '69061': [], \n",
    "    '69360': [254, 255], \n",
    "    '69659': [132, 133, 252, 253], \n",
    "    '69958': [271, 272],\n",
    "\n",
    "    # 55.8 K 25 mW Positive Field Sweep\n",
    "    '70797': [47, 48, 216, 265, 266], \n",
    "    '71096': [], \n",
    "    '71395': [], \n",
    "    '71694': [35, 36], \n",
    "    '71993': [265, 266],\n",
    "    '72292': [],\n",
    "\n",
    "    # --- Temperature Sweeps ---\n",
    "    \n",
    "    # -29 mT 10 mW Temp Sweep\n",
    "    '61221': [], \n",
    "    '61759': [], \n",
    "    '62417': [],\n",
    "\n",
    "    # -29 mT 25 mW Temp Sweep\n",
    "    '65766': [], \n",
    "    '65228': [], \n",
    "    '64690': [], \n",
    "    '64152': [], \n",
    "    '63614': [], \n",
    "    '63076': [],\n",
    "\n",
    "    # +29 mT 25 mW Temp Sweep\n",
    "    '76899': [], \n",
    "    '76361': [], \n",
    "    '75823': [], \n",
    "    '75285': [],\n",
    "\n",
    "    # -29 mT 50 mW Temp Sweep\n",
    "    '52666': [], \n",
    "    '59887': [], \n",
    "    '52128': [], \n",
    "    '59349': [], \n",
    "    '51590': [], \n",
    "    '58811': [], \n",
    "    '51052': [], \n",
    "    '58273': [], \n",
    "    '50514': [], \n",
    "    '57735': [], \n",
    "    '49976': [], \n",
    "    '57197': [], \n",
    "    '49438': [],\n",
    "\n",
    "    # +29 mT 50 mW Temp Sweep\n",
    "    '47963': [], \n",
    "    '47425': [], \n",
    "    '67624': [], \n",
    "    '46887': [], \n",
    "    '67086': [], \n",
    "    '46349': [], \n",
    "    '45811': [], \n",
    "    '66670': [], \n",
    "    '45268': [], \n",
    "    '44730': [], \n",
    "    '44192': []\n",
    "}\n",
    "\n",
    "print(filtered_indices.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"easy\": 69958, \"med\": 56059, \"hard\": 46349\n",
    "########### REFERENCE FRAME ##############\n",
    "#   0deg is the +y axis\n",
    "#   postive phi is cw rotation\n",
    "#   ccw rotation caused by negative field\n",
    "#   cw rotation caused by positive field\n",
    "#   TLDR: positive fields have positive phis and negative fields have negative phis\n",
    "\n",
    "numor = 69958\n",
    "path_to_npz = f'/Users/cadenmyers/billingelab/dev/sym_adapted_filts/experimental_data/npz_sept_numor_data/{numor}.npz'\n",
    "data = np.load(path_to_npz)['data']\n",
    "print(data[0].shape)\n",
    "print(movie_to_title[str(numor)])\n",
    "n_folds=6\n",
    "h, w = data[0].shape[:2]\n",
    "cx, cy = w // 2, h // 2\n",
    "x_grid, y_grid = np.meshgrid(np.arange(w), np.arange(h))\n",
    "# handle slight offcentering of DPs\n",
    "shift_x, shift_y = 0, -2\n",
    "x_grid_shifted = x_grid - shift_x\n",
    "y_grid_shifted = y_grid - shift_y\n",
    "DATA_THETA = np.arctan2(y_grid_shifted - cy, x_grid_shifted - cx) # switch to arctan(x/y) for reference frame\n",
    "OFFSET_ADJUSTMENT = int(360/n_folds)\n",
    "OFFSET_ADJUSTMENT_rad = np.deg2rad(OFFSET_ADJUSTMENT)\n",
    "resolution=10.8\n",
    "\n",
    "def find_k_value(resolution=resolution, n_folds=n_folds):\n",
    "    '''finds k given resolution(deg).\n",
    "    This assumes FWHM_experiment is approx equal to FWHM_filter'''\n",
    "    res_rad = np.deg2rad(resolution)\n",
    "    k = np.log(1/2) / (np.log(np.cos((n_folds/4*res_rad))**2))\n",
    "    # print('k=', k)\n",
    "    return k\n",
    "k = find_k_value()\n",
    "\n",
    "def filter_function(k, offset, n_folds=n_folds):\n",
    "    filter = np.exp(k * np.log((np.cos(n_folds / 2 * (DATA_THETA + offset)))**2)) # changed cosine to sine for reference frame\n",
    "    # plt.imshow(filter)\n",
    "    # plt.title(f'n_folds={n_folds}, k={k}')\n",
    "    # plt.show()\n",
    "    return filter\n",
    "\n",
    "def normalize_min_max(data):\n",
    "    try:\n",
    "        array = data.copy()\n",
    "    except AttributeError:\n",
    "        array = np.array(data, copy=True)\n",
    "    if array.size == 0:\n",
    "        raise ValueError(\"Cannot normalize an empty array.\")\n",
    "    array_min = np.min(array)\n",
    "    array_max = np.max(array)\n",
    "    if array_max == array_min:\n",
    "        return np.zeros_like(array)\n",
    "    norm_array = (array - array_min) / (array_max - array_min)\n",
    "    return norm_array\n",
    "\n",
    "def mask_and_blur_images(movie, inner_radius=16, outer_radius=30, sigma=0.65):\n",
    "    for i in range(movie.shape[0]):\n",
    "        x, y = np.meshgrid(np.arange(128), np.arange(128))\n",
    "        radius = np.sqrt((x - 64)**2 + (y - 62)**2)\n",
    "        mask1 = radius <= inner_radius\n",
    "        mask2 = radius >= outer_radius\n",
    "        masked_data = movie[i].copy()\n",
    "        masked_data[mask1] = 0\n",
    "        masked_data2 = masked_data.copy()\n",
    "        masked_data2[mask2] = 0\n",
    "        blurred_data = gaussian_filter(masked_data2, sigma=sigma)\n",
    "        movie[i] = blurred_data\n",
    "    return movie\n",
    "\n",
    "dps = mask_and_blur_images(data)\n",
    "# plt.imshow(normalize_min_max(dps[0]) + filter_function(200, 0, n_folds=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SECOND DERIVATIVE FUNCTIONS AND SUCH\n",
    "\n",
    "# Function 2: get correct period indices\n",
    "def get_correct_period_indices(loss_values):\n",
    "    \"\"\"Finds the correct period indices based on the maximum value in the loss values.\n",
    "    If only one max index is found, adds adjacent indices at -60 or +60.\"\"\"\n",
    "    indices = [i for i, loss in enumerate(loss_values) if loss == max(loss_values)]\n",
    "    if len(indices) > 1:\n",
    "        return sorted(indices[:2])\n",
    "    index = indices[0]\n",
    "    adjacent_indices = [i for i in [index + OFFSET_ADJUSTMENT, index - OFFSET_ADJUSTMENT] if 0 <= i < len(loss_values)]\n",
    "    return sorted([index] + adjacent_indices)\n",
    "\n",
    "# Function 3: Discrete search for number of domains and get approximate offset positions\n",
    "def compute_loss_near_offset1(intensity, prev_offset):\n",
    "    \"\"\"Compute the loss, first derivative, and second derivative for a range of offsets\n",
    "    around the previous offset, selecting the closest periodic range.\n",
    "\n",
    "    prev_offset should be in radians\"\"\"\n",
    "    \n",
    "    # Define the periodic range and step size for sweeping through offset angles\n",
    "    angle_period = np.deg2rad(360/n_folds)\n",
    "    step_size_radians = np.deg2rad(1)\n",
    "    offset_values = np.arange(prev_offset-angle_period, prev_offset+angle_period, step_size_radians)\n",
    "    loss_values = []\n",
    "    for offset in offset_values:\n",
    "        evaluate_image_theta = filter_function(k, offset)\n",
    "        loss = -(intensity * evaluate_image_theta).sum()\n",
    "        loss_values.append(loss.item())\n",
    "    first_derivative = np.gradient(loss_values)\n",
    "    second_derivative = np.gradient(first_derivative)\n",
    "    selected_indices = get_correct_period_indices(loss_values)\n",
    "\n",
    "    # Select the appropriate range of offsets, losses, and derivatives based on the period indices\n",
    "    offset_values = np.array(offset_values[selected_indices[0]:selected_indices[1]+1])\n",
    "    loss_values = np.array(loss_values[selected_indices[0]:selected_indices[1]+1])\n",
    "    first_derivative = np.array(first_derivative[selected_indices[0]:selected_indices[1]+1])\n",
    "    second_derivative = np.array(second_derivative[selected_indices[0]:selected_indices[1]+1])\n",
    "\n",
    "    return offset_values, loss_values, first_derivative, second_derivative\n",
    "\n",
    "# Function 4: Get approximate offset positions through finding local maxima in second derivatives\n",
    "def get_approx_offset_values(offset_values, second_derivative):\n",
    "    \"\"\"Identify approximate offset positions by finding local maxima and inflection points in the second derivative.\"\"\"\n",
    "    local_maxima_indices = argrelextrema(second_derivative, np.greater)[0]\n",
    "    # Remove indices close to the edges because these local maximas might be introduced by the local maxima from the phase change\n",
    "    filtered_indices = local_maxima_indices[(local_maxima_indices >= 5) & (local_maxima_indices <= len(second_derivative) - 6)]\n",
    "    indices_info = [(index, offset_values[index], second_derivative[index]) for index in filtered_indices]\n",
    "    # Sort by second derivative values (descending) and return top two offsets\n",
    "    sorted_maxima = sorted(indices_info, key=lambda x: x[2], reverse=True)\n",
    "    approx_offset_values = [offset for _, offset, _ in sorted_maxima][:2]\n",
    "    return approx_offset_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STORING FOR BACKUP, DELETE LATER\n",
    "def grid_search_offset(\n",
    "    dps,\n",
    "    tolerance_forward,\n",
    "    tolerance_reverse,\n",
    "    jump_threshold_offset1,\n",
    "    jump_threshold_offset2,\n",
    "    offset_step=0.5,\n",
    "):\n",
    "    '''\n",
    "    positive angles = forward rotation\n",
    "    negative angles = reverse rotation\n",
    "    returns offset1 and offset2 in degrees\n",
    "    '''\n",
    "    optimal_offsets1 = []\n",
    "    optimal_offsets2 = []\n",
    "    prev_offset1 = 0\n",
    "    prev_offset2 = 0\n",
    "\n",
    "    for index, dp in enumerate(dps):\n",
    "        loss_list1 = []\n",
    "        offset_list_deg1 = []\n",
    "        # find initial offset\n",
    "        if index == 0:\n",
    "            offset1_angles_deg = np.arange(-60, 60, offset_step)\n",
    "        else:\n",
    "            offset1_angles_deg = np.arange(prev_offset1 - tolerance_reverse, prev_offset1 + tolerance_forward, offset_step)\n",
    "\n",
    "        # Compute loss function\n",
    "        for offset1 in offset1_angles_deg:\n",
    "            offset_rad = np.deg2rad(offset1)  # convert to radians\n",
    "            filt = filter_function(k, offset_rad)\n",
    "            loss = -(dp * filt).sum()\n",
    "            loss_list1.append(loss)\n",
    "            offset_list_deg1.append(offset1)\n",
    "            if offset1 % 5 ==0:\n",
    "                print(offset1)\n",
    "                plt.imshow(filt + normalize_min_max(dp))\n",
    "                plt.show()\n",
    "        min_loss_idx = loss_list1.index(min(loss_list1))\n",
    "        best_offset1 = offset_list_deg1[min_loss_idx]\n",
    "        # Convert to NumPy arrays\n",
    "        loss_array = np.array(loss_list1)\n",
    "        offset_array = np.array(offset_list_deg1)\n",
    "        # Global argmax\n",
    "        global_argmax_idx = np.argmax(loss_array)\n",
    "        global_argmax_offset = offset_array[global_argmax_idx]\n",
    "\n",
    "        # Local argmax\n",
    "        local_argmax_indices = argrelextrema(loss_array, np.greater)[0]\n",
    "        local_argmax_offsets = offset_array[local_argmax_indices]\n",
    "\n",
    "        # print(f\"{index}: Global argmax: {global_argmax_offset}, Local argmax: {local_argmax_offsets}\")\n",
    "\n",
    "        # Correct overrotations of 60 degrees for offset1\n",
    "        delta1 = abs(global_argmax_offset - prev_offset1)\n",
    "        if delta1 > jump_threshold_offset1 and len(local_argmax_offsets) > 0:\n",
    "            best_offset1 = min(local_argmax_offsets, key=lambda x: abs(x - prev_offset1))\n",
    "            # print(f\"{index}: Threshold exceeded for offset1. Using closest local max: {best_offset1}\")\n",
    "        else:\n",
    "            best_offset1 = global_argmax_offset\n",
    "\n",
    "        filt1 = filter_function(k, np.deg2rad(best_offset1))\n",
    "        filt1 = np.where(filt1 > 0.01, 0, 1)\n",
    "        dp_filtered = dp * filt1\n",
    "\n",
    "        # Use second derivative to determine the number of domains\n",
    "        offset_range, loss_values, first_derivative, second_derivative = compute_loss_near_offset1(dp, np.deg2rad(best_offset1))\n",
    "        approx_offset_values = get_approx_offset_values(offset_range, second_derivative)\n",
    "        number_of_domains = len(approx_offset_values)\n",
    "        loss_list2 = []\n",
    "        offset_list_deg2 = []\n",
    "        if number_of_domains == 1:\n",
    "            offset2_angles_deg = np.arange(prev_offset2 - 40, prev_offset2 + 40, offset_step)\n",
    "            for offset2 in offset2_angles_deg:\n",
    "                offset_rad = np.deg2rad(offset2)\n",
    "                filt2 = filter_function(k, offset_rad)\n",
    "                loss = -(dp * filt2).sum()\n",
    "                loss_list2.append(loss)\n",
    "                offset_list_deg2.append(offset2)\n",
    "            min_loss_idx = loss_list2.index(min(loss_list2))\n",
    "            best_offset2 = offset_list_deg2[min_loss_idx]\n",
    "        else:\n",
    "            # Second domain search\n",
    "            offset2_angles_deg = np.arange(prev_offset2 - tolerance_reverse, prev_offset2 + tolerance_forward, offset_step)\n",
    "            for offset2 in offset2_angles_deg:\n",
    "                offset_rad = np.deg2rad(offset2)\n",
    "                filt2 = filter_function(k, offset_rad)\n",
    "                loss = -(dp_filtered * filt2).sum()\n",
    "                loss_list2.append(loss)\n",
    "                offset_list_deg2.append(offset2)\n",
    "            min_loss_idx = loss_list2.index(min(loss_list2))\n",
    "            best_offset2 = offset_list_deg2[min_loss_idx]\n",
    "\n",
    "            # Correct overrotations of 60 degrees for offset2\n",
    "            delta2 = abs(best_offset2) - abs(prev_offset2)\n",
    "            if delta2 > jump_threshold_offset2:\n",
    "                best_offset2 -= 60\n",
    "                print(f\"{index}: Threshold2 exceeded for offset2. Adjusting by -60 degrees: {best_offset2}\")\n",
    "                print(delta2, '>', jump_threshold_offset2)\n",
    "\n",
    "        # plotting\n",
    "        norm_int = normalize_min_max(dp)\n",
    "        filt1 = filter_function(k, np.deg2rad(best_offset1))\n",
    "        filt2 = filter_function(k, np.deg2rad(best_offset2))\n",
    "        signal = norm_int + filt1 + 2*filt2\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 6))\n",
    "        axs[0].imshow(signal, cmap='viridis', vmin=0, vmax=2)\n",
    "        axs[1].imshow(norm_int, cmap='viridis')\n",
    "        axs[2].imshow(dp_filtered)\n",
    "        plt.show()\n",
    "        print(f'{index*10}s: ', best_offset1, best_offset2)\n",
    "\n",
    "        optimal_offsets1.append(best_offset1)\n",
    "        optimal_offsets2.append(best_offset2)\n",
    "        prev_offset1 = best_offset1\n",
    "        prev_offset2 = best_offset2\n",
    "    return optimal_offsets1, optimal_offsets2\n",
    "\n",
    "tolerance_forward = 20\n",
    "tolerance_reverse = 5\n",
    "jump_threshold_offset1 = 20\n",
    "jump_threshold_offset2 = 20\n",
    "offset1, offset2 = grid_search_offset(dps[:2], offset_step=0.5, tolerance_forward=tolerance_forward, tolerance_reverse=tolerance_reverse, \n",
    "                                        jump_threshold_offset1=jump_threshold_offset1, jump_threshold_offset2=jump_threshold_offset2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search_offset(\n",
    "    dps,\n",
    "    tolerance_forward,\n",
    "    tolerance_reverse,\n",
    "    jump_threshold_offset1,\n",
    "    jump_threshold_offset2,\n",
    "    n_folds=6,\n",
    "    offset_step=0.5,\n",
    "):\n",
    "    '''\n",
    "    positive angles = cw rotation\n",
    "    negative angles = ccw rotation\n",
    "    returns offset1 and offset2 in degrees\n",
    "    '''\n",
    "    optimal_offsets1 = []\n",
    "    optimal_offsets2 = []\n",
    "    prev_offset1 = 0\n",
    "    prev_offset2 = 0\n",
    "\n",
    "    for index, dp in enumerate(dps):\n",
    "        loss_list1 = []\n",
    "        offset_list_deg1 = []\n",
    "        # find initial offset\n",
    "        if index == 0:\n",
    "            offset1_angles_deg = np.arange(-360/n_folds, 360/n_folds, offset_step)\n",
    "        else:\n",
    "            offset1_angles_deg = np.arange(prev_offset1 - tolerance_reverse, prev_offset1 + tolerance_forward, offset_step)\n",
    "        ######## CALCULATE FIRST OFFSET #########\n",
    "        # Compute loss function\n",
    "        for offset1 in offset1_angles_deg:\n",
    "            offset_rad = np.deg2rad(offset1)  # convert to radians\n",
    "            filt = filter_function(k, offset_rad)\n",
    "            loss = -(dp * filt).sum()\n",
    "            loss_list1.append(loss)\n",
    "            offset_list_deg1.append(offset1)\n",
    "        # Convert to NumPy arrays\n",
    "        loss_array = np.array(loss_list1)\n",
    "        offset_array = np.array(offset_list_deg1)\n",
    "        # Global argmax\n",
    "        global_argmax_idx = np.argmax(loss_array)\n",
    "        global_argmax_offset = offset_array[global_argmax_idx]\n",
    "        # Local argmax\n",
    "        local_argmax_indices = argrelextrema(loss_array, np.greater)[0]\n",
    "        local_argmax_offsets = offset_array[local_argmax_indices]\n",
    "        # print(f\"{index}: Global argmax: {global_argmax_offset}, Local argmax: {local_argmax_offsets}\")\n",
    "\n",
    "        # Correct overrotations of 60 degrees for offset1\n",
    "        delta1 = abs(global_argmax_offset - prev_offset1)\n",
    "        if delta1 > jump_threshold_offset1 and len(local_argmax_offsets) > 0:\n",
    "            best_offset1 = min(local_argmax_offsets, key=lambda x: abs(x - prev_offset1))\n",
    "            # print(f\"{index}: Threshold exceeded for offset1. Using closest local max: {best_offset1}\")\n",
    "        else:\n",
    "            best_offset1 = global_argmax_offset\n",
    "\n",
    "        filt1 = filter_function(k, np.deg2rad(best_offset1))\n",
    "        filt1 = np.where(filt1 > 0.05, 0, 1)\n",
    "        dp_filtered = dp * filt1\n",
    "\n",
    "        ######### CALCULATE SECOND OFFSET #########\n",
    "        # Use second derivative to determine the number of domains\n",
    "        offset_range, loss_values, first_derivative, second_derivative = compute_loss_near_offset1(dp, np.deg2rad(best_offset1))\n",
    "        approx_offset_values = get_approx_offset_values(offset_range, second_derivative)\n",
    "        number_of_domains = len(approx_offset_values)\n",
    "        if number_of_domains == 1:\n",
    "            best_offset2 = prev_offset2 + best_offset1 % 360/n_folds  # mod60 term is added to account for the\n",
    "        else:                                               # movement of offset2 from previous to current frame\n",
    "            # Second domain search\n",
    "            loss_list2 = []\n",
    "            offset_list_deg2 = []\n",
    "            offset2_angles_deg = np.arange(prev_offset2 - tolerance_reverse, prev_offset2 + tolerance_forward, offset_step)\n",
    "            for offset2 in offset2_angles_deg:\n",
    "                offset_rad = np.deg2rad(offset2)\n",
    "                filt2 = filter_function(k, offset_rad)\n",
    "                loss = -(dp_filtered * filt2).sum()\n",
    "                loss_list2.append(loss)\n",
    "                offset_list_deg2.append(offset2)\n",
    "            min_loss_idx = loss_list2.index(min(loss_list2))\n",
    "            best_offset2 = offset_list_deg2[min_loss_idx]\n",
    "\n",
    "            # Correct overrotations of 60 degrees for offset2\n",
    "            delta2 = abs(best_offset2) - abs(prev_offset2)\n",
    "            # print(f\"{index}: best_offset2 = {best_offset2}, prev_offset2 = {prev_offset2}, delta2 = {delta2}\")\n",
    "            if delta2 > jump_threshold_offset2:\n",
    "                best_offset2 -= 360/n_folds\n",
    "                print(f\"{index}: Threshold2 exceeded for offset2. Adjusting by -{360/n_folds} degrees: {best_offset2}\")\n",
    "                print(delta2, '>', jump_threshold_offset2)\n",
    "\n",
    "        # plotting\n",
    "        # norm_int = normalize_min_max(dp)\n",
    "        # filt1 = filter_function(k, np.deg2rad(best_offset1))\n",
    "        # filt2 = filter_function(k, np.deg2rad(best_offset2))\n",
    "        # signal = norm_int + filt1 + 2*filt2\n",
    "        # fig, axs = plt.subplots(1, 3, figsize=(12, 6))\n",
    "        # axs[0].imshow(signal, cmap='viridis', vmin=0, vmax=2)\n",
    "        # axs[1].imshow(norm_int, cmap='viridis')\n",
    "        # axs[2].imshow(dp_filtered)\n",
    "        # plt.show()\n",
    "        # print(f'{index*10}s: ', best_offset1, best_offset2)\n",
    "\n",
    "        optimal_offsets1.append(best_offset1)\n",
    "        optimal_offsets2.append(best_offset2)\n",
    "        prev_offset1 = best_offset1\n",
    "        prev_offset2 = best_offset2\n",
    "    return optimal_offsets1, optimal_offsets2\n",
    "\n",
    "\n",
    "# Fix jump thresholding and then fix the new frame of reference\n",
    "tolerance_forward = 20\n",
    "tolerance_reverse = 5\n",
    "jump_threshold_offset1 = 20\n",
    "jump_threshold_offset2 = 20\n",
    "offset1, offset2 = grid_search_offset(dps, offset_step=0.5, tolerance_forward=tolerance_reverse, tolerance_reverse=tolerance_forward, \n",
    "                                        jump_threshold_offset1=jump_threshold_offset1, jump_threshold_offset2=jump_threshold_offset2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST BELOW FOR LOOP ON INDIVIDUAL SWEEPS\n",
    "path_to_npzs = '/Users/cadenmyers/billingelab/dev/sym_adapted_filts/experimental_data/npz_sept_numor_data/'\n",
    "\n",
    "tolerance_forward = 20\n",
    "jump_threshold_offset1 = 20\n",
    "jump_threshold_offset2 = 20\n",
    "\n",
    "def process_numors(numors, tolerance_reverse, filtered_indices=filtered_indices, tolerance_forward=tolerance_forward, \n",
    "                   jump_threshold_offset1=jump_threshold_offset1, jump_threshold_offset2=jump_threshold_offset2, \n",
    "                   path_to_npzs=path_to_npzs):\n",
    "    \"\"\"Processes a list of numors, removes bad DPs, applies masking, and calculates offsets.\n",
    "    Returns:\n",
    "        offsets_info (dict): {numor: {\"offset1\": np.array, \"offset2\": np.array}}\n",
    "    \"\"\"\n",
    "    offsets_info = {}\n",
    "    print(f'Processing {len(numors)} numors...')\n",
    "    print(f'Reverse tolerance= {tolerance_reverse} deg')\n",
    "\n",
    "    original_tolerance_forward = tolerance_forward\n",
    "    original_tolerance_reverse = tolerance_reverse\n",
    "    for numor in numors:\n",
    "        # logic for cw (pos) or ccw (neg) skyrmion motion, ccw is default\n",
    "        if '+' in movie_to_title[str(numor)] or 'Positive' in movie_to_title[str(numor)]:\n",
    "            tolerance_forward, tolerance_reverse = tolerance_reverse, tolerance_forward\n",
    "            print('   Positive field detected, swapping tolerances -->', movie_to_title[str(numor)])\n",
    "            print('   tolerance_forward <--> tolerance_reverse')\n",
    "\n",
    "        print(f'Processing numor: {numor}')\n",
    "        data = np.load(f\"{path_to_npzs}{numor}.npz\")['data']\n",
    "        # Remove bad DPs if numor exists in filtered_indices\n",
    "        if numor in filtered_indices:\n",
    "            for index in sorted(filtered_indices[numor], reverse=True):  # Reverse to avoid index shifting issues\n",
    "                print(f'Deleting index {index} from {numor}')\n",
    "                data = np.delete(data, index, axis=0)\n",
    "        dps = mask_and_blur_images(data)\n",
    "        offsets1, offsets2 = grid_search_offset(dps, offset_step=0.5, tolerance_forward=tolerance_forward, \n",
    "                                                tolerance_reverse=tolerance_reverse, jump_threshold_offset1=jump_threshold_offset1, \n",
    "                                                jump_threshold_offset2=jump_threshold_offset2)\n",
    "        offsets_info[numor] = {\"offset1\": offsets1, \"offset2\": offsets2}\n",
    "        tolerance_forward, tolerance_reverse = original_tolerance_forward, original_tolerance_reverse\n",
    "    print('Processing complete.')\n",
    "    return offsets_info  # Dictionary: {numor: {\"offset1\": array, \"offset2\": array}}\n",
    "\n",
    "\n",
    "def plot_numor_offsets(offsets_info, tolerance_reverse, tolerance_forward=tolerance_forward, \n",
    "                       jump_threshold_offset1=jump_threshold_offset1, jump_threshold_offset2=jump_threshold_offset2):\n",
    "    \"\"\"Plots offsets for all processed numors.\"\"\"\n",
    "    numors = list(offsets_info.keys())\n",
    "    colors = [plt.cm.viridis(i / len(numors)) for i in range(len(numors))]\n",
    "    print(\"Generating plots...\")\n",
    "    for i, (numor, offsets) in enumerate(offsets_info.items()):\n",
    "        offset1, offset2 = offsets[\"offset1\"], offsets[\"offset2\"]\n",
    "        plt.plot(offset1 - offset1[0], label=f'offset1 {numor}', color=colors[i])\n",
    "        plt.plot(offset2 - offset2[0], color=colors[i], linestyle='dotted')\n",
    "    plt.title(f\"tolerance_forward={tolerance_forward}, tolerance_reverse={tolerance_reverse}\\n\"\n",
    "              f\"jump_threshold1={jump_threshold_offset1}, jump_threshold2={jump_threshold_offset2}\")\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(\"Offset (degrees)\")\n",
    "    plt.minorticks_on()\n",
    "    plt.tick_params(direction='in')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'data/reverse_tol_{tolerance_reverse}_numors_ratchet_model.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = '55.3 K 50 mW Negative Field Sweep'\n",
    "# numors = folder_movies[dataset]\n",
    "numors = [46349, 69958, 56059] #pos, neg, neg\n",
    "print(numors)\n",
    "tols = [8, 7, 6, 5, 4, 3]\n",
    "for tol_reverse in tols:\n",
    "    print(f'tol_reverse={tol_reverse}')\n",
    "    offset_info = process_numors(numors, tol_reverse)\n",
    "    for numor, offsets in offset_info.items():\n",
    "        np.savez(f\"data/reverse_tol_{tol_reverse}_{numor}_offsets.npz\", \n",
    "                 **{f\"offset1\": offsets[\"offset1\"], \n",
    "                    f\"offset2\": offsets[\"offset2\"]})\n",
    "    plot_numor_offsets(offset_info, tol_reverse)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numor = '61221'\n",
    "path_to_offsets = '/Users/cadenmyers/billingelab/dev/sym_adapted_filts/working_code/ratchet_model/data/'\n",
    "filename = f'ratchet_offsets_{numor}.npz'\n",
    "offset1 = -np.load(path_to_offsets + filename)['offset1']\n",
    "offset2 = -np.load(path_to_offsets + filename)['offset2']\n",
    "\n",
    "# offsets1 = np.rad2deg(offsets1)\n",
    "# print(offsets1)\n",
    "# offsets2 = np.deg2rad(np.array(offset2))\n",
    "# print(offset1[:5])\n",
    "# print(offset2[:5])\n",
    "# offsets2 = np.rad2deg(offsets2)\n",
    "# print(offsets2)\n",
    "\n",
    "def interactive_plot(frame_idx):\n",
    "    '''Plot the intensity data and filter images with respect to the selected frame index.'''\n",
    "    offset1_rad = np.deg2rad(offset1[frame_idx])\n",
    "    offset2_rad = np.deg2rad(offset2[frame_idx])\n",
    "    n_folds = 6\n",
    "    k=find_k_value(n_folds=n_folds)\n",
    "    image1 = filter_function(k, offset1_rad, n_folds=n_folds)\n",
    "    image2 = filter_function(k, offset2_rad, n_folds=n_folds)\n",
    "    dp_norm = normalize_min_max(dps[frame_idx])\n",
    "    # Create figure and axes\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 5))\n",
    "\n",
    "    # first domain\n",
    "    ax1.imshow(image1 + dp_norm)\n",
    "    # ax1.imshow(image1 + 2*image2 + normalize_min_max(dps[frame_idx]), origin=\"lower\")\n",
    "    ax1.set_title(f\"Frame {frame_idx+1}: first domain\")\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    # second domain\n",
    "    ax2.imshow(image2 + dp_norm)\n",
    "    ax2.set_title(\"2nd domain\")\n",
    "\n",
    "    # raw DP\n",
    "    ax3.imshow(dp_norm)\n",
    "    ax3.set_title(f\"Frame {frame_idx+1}: Intensity Data\")\n",
    "    ax3.axis(\"off\")\n",
    "    # Update the figure title with offset values\n",
    "    fig.suptitle(f\"numor={numor}, \\\n",
    "                 Offset1={round(offset1[frame_idx], 2)}°, \\\n",
    "                Offset2={round(offset2[frame_idx], 2)}°, \\\n",
    "                Time={(frame_idx+1)*10}s, \\\n",
    "                Reverse tol={tolerance_reverse}\")\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create interactive plot with sliders for frame index\n",
    "interact(\n",
    "    interactive_plot,\n",
    "    frame_idx=IntSlider(value=0, min=0, max=len(dps)-1, step=1, description='Frame Index')\n",
    ");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ratchet on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "cmap = cm.viridis\n",
    "\n",
    "# neg field 63614 moves ccw\n",
    "# pos field 75823 moves cw\n",
    "\n",
    "# tolerance_ccw=40\n",
    "# tolerance_cw=5\n",
    "jump_threshold_offset1 = 15\n",
    "jump_threshold_offset2 = 50\n",
    "path_to_npzs = '/Users/cadenmyers/billingelab/dev/sym_adapted_filts/experimental_data/npz_sept_numor_data/'\n",
    "for title, numor_list in folder_movies.items():\n",
    "    # Initialize a list to store results for plotting\n",
    "    all_offsets = []\n",
    "    colors = [cmap(i / len(numor_list)) for i in range(len(numor_list))]\n",
    "    print(f'working on numors {numor_list}')\n",
    "    tolerance_ccw=40 # default is for negative field (ccw rotation)\n",
    "    tolerance_cw=5\n",
    "    if '+' in title or 'Positive' in title:\n",
    "        tolerance_ccw, tolerance_cw = tolerance_cw, tolerance_ccw\n",
    "        print('positive field')\n",
    "    for numor in numor_list:\n",
    "        # Load the numor data using np.load()\n",
    "        data = np.load(path_to_npzs + numor +'.npz')['data']\n",
    "        # remove bad DPs from numor\n",
    "        for index in filtered_indices[numor]:\n",
    "            print(f'deleted index {index} from {numor}')\n",
    "            data = np.delete(data, index, axis=0)\n",
    "        dps = mask_and_blur_images(data)\n",
    "        # Run grid_search_offset function with the loaded data\n",
    "\n",
    "\n",
    "        offset1, offset2 = grid_search_offset(dps, offset_step=0.5, tolerance_ccw=tolerance_ccw, tolerance_cw=tolerance_cw, \n",
    "                                        threshold_offset1=jump_threshold_offset1, jump_threshold_offset2=jump_threshold_offset2)\n",
    "        np.savez(f\"{numor}_ratchet_offsets.npz\", offset1=offset1, offset2=offset2)\n",
    "        # Append the result for plotting\n",
    "        all_offsets.append((numor, offset1, offset2))\n",
    "        print(f'finished numor {numor}')\n",
    "    print('Next!')\n",
    "    # Plot all numors for the current key\n",
    "    for i, (numor, offset1, offset2) in enumerate(all_offsets):\n",
    "        plt.plot(offset1-offset1[0], label='offset1 '+numor, color=colors[i])\n",
    "        plt.plot(offset2-offset2[0], color=colors[i], linestyle='dotted')\n",
    "    plt.title(f\"{title}\")\n",
    "    plt.xlabel(\"index\")\n",
    "    plt.ylabel(\"Offset (degrees)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    # plt.savefig(f'data/{title}_ratchet_model.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hand clicked\n",
    "seed_path = \"/Users/cadenmyers/billingelab/dev/sym_adapted_filts/working_code/seed_generating/seed_data/\"\n",
    "analysis_path = \"/Users/cadenmyers/billingelab/dev/sym_adapted_filts/analysis-generated_data/\"\n",
    "\n",
    "numor = '46349'\n",
    "# Define file paths\n",
    "cm_offset1_path = f\"{seed_path}cm_{numor}_offset1_seed.npz\"\n",
    "cm_offset2_path = f\"{seed_path}cm_{numor}_offset2_seed.npz\"\n",
    "yc_offset1_path = f\"{seed_path}yc_{numor}_offset1_seed.npz\"\n",
    "yc_offset2_path = f\"{seed_path}yc_{numor}_offset2_seed.npz\"\n",
    "dr_offset1_path = f\"{seed_path}dr_{numor}_offset1_seed.npz\"\n",
    "dr_offset2_path = f\"{seed_path}dr_{numor}_offset2_seed.npz\"\n",
    "nc_offset1_path = f\"{seed_path}nc_{numor}_offset1_seed.npz\"\n",
    "nc_offset2_path = f\"{seed_path}nc_{numor}_offset2_seed.npz\"\n",
    "oob_offset1_path = f\"{analysis_path}{numor}_offsets.npz\"\n",
    "oob_offset2_path = f\"{analysis_path}{numor}_offsets.npz\"\n",
    "\n",
    "# Load data\n",
    "offset1cm = np.load(cm_offset1_path)['data']\n",
    "offset2cm = np.load(cm_offset2_path)['data']\n",
    "offset1yc = np.load(yc_offset1_path)['data']\n",
    "offset2yc = np.load(yc_offset2_path)['data']\n",
    "offset1dr = np.load(dr_offset1_path)['data']\n",
    "offset2dr = np.load(dr_offset2_path)['data']\n",
    "offset1nc = np.load(nc_offset1_path)['data']\n",
    "offset2nc = np.load(nc_offset2_path)['data']\n",
    "offset1oob = np.load(oob_offset1_path)['offset1']\n",
    "offset2oob = np.load(oob_offset2_path)['offset2']\n",
    "\n",
    "window_length = 5\n",
    "polyorder=4\n",
    "def compute_smoothed_derivative(offset, window_length=window_length, polyorder=polyorder):\n",
    "    '''compute velocity of data after savgol_filter is applied, assumes frame rate of 10s'''\n",
    "    smoothed_angle = savgol_filter(offset, window_length=window_length, polyorder=polyorder)\n",
    "    time = (np.arange(offset.shape[0])+1)*10\n",
    "    smoothed_derivative = (np.gradient(smoothed_angle, time))\n",
    "    return smoothed_derivative\n",
    "\n",
    "colors = {\n",
    "    \"cm\": \"blue\",\n",
    "    \"yc\": \"red\",\n",
    "    \"dr\": \"green\",\n",
    "    \"nc\": \"purple\",\n",
    "    \"oob\": 'orange',\n",
    "    'ratchet': 'hotpink'\n",
    "}\n",
    "\n",
    "# plot over different tolerances\n",
    "tols = [5]#, 7, 6, 5, 4, 3]\n",
    "plt.figure(figsize=(7,7))\n",
    "for i, tol in enumerate(tols):\n",
    "    viri = [plt.cm.viridis(i / len(tols)) for i in range(len(tols))]\n",
    "    offset1r = np.load(f'/Users/cadenmyers/billingelab/dev/sym_adapted_filts/working_code/ratchet_model/data/reverse_tol_{tol}_{numor}_offsets.npz')['offset1']\n",
    "    offset2r = np.load(f'/Users/cadenmyers/billingelab/dev/sym_adapted_filts/working_code/ratchet_model/data/reverse_tol_{tol}_{numor}_offsets.npz')['offset2']\n",
    "    plt.plot(-(offset1r - offset1r[0]), color=viri[i], label=f'offset1 ratchet tol={tol}')\n",
    "    # velo2 = compute_smoothed_derivative(offset2r)\n",
    "    # velo = compute_smoothed_derivative(offset1r)\n",
    "    # plt.plot(velo, label=f'velo {numor}')\n",
    "    # plt.plot(velo2, linestyle=':')\n",
    "    plt.plot(-(offset2r - offset2r[0]), color=viri[i], linestyle=':')\n",
    "\n",
    "plt.plot(offset1-offset1[0], color= colors['ratchet'])\n",
    "plt.plot(offset2-offset2[0], color=colors['ratchet'], linestyle=':')\n",
    "# plt.plot(offset1oob - offset1oob[0], color=colors['oob'], label='offset1 GD')\n",
    "# # plt.plot(offset2oob - offset2oob[0], color=colors['oob'], linestyle=':')\n",
    "# plt.plot(offset1cm - offset1cm[0], label='offset1 cm', color=colors['cm'])\n",
    "# # plt.plot(offset2cm - offset2cm[0], color=colors['cm'], linestyle=':')\n",
    "# plt.plot(offset1yc - offset1yc[0], label='offset1 yc', color=colors[\"yc\"])\n",
    "# # plt.plot(offset2yc - offset2yc[0], color=colors[\"yc\"], linestyle=':')\n",
    "# plt.plot(offset1dr - offset1dr[0], label='offset1 dr', color=colors[\"dr\"])\n",
    "# # plt.plot(offset2dr - offset2dr[0], color=colors[\"dr\"], linestyle=':')\n",
    "# plt.plot(offset1nc-offset1nc[0], label=f'offset1 nc', color=colors[\"nc\"])\n",
    "# # plt.plot(offset2nc-offset2nc[0], color=colors[\"nc\"], linestyle=':')\n",
    "\n",
    "plt.grid(True)\n",
    "# plt.ylabel('offset')\n",
    "plt.ylabel('angular velo deg/sec')\n",
    "plt.xlabel('index')\n",
    "plt.legend()\n",
    "plt.title(f'{movie_to_title[str(numor)]}')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # plot over different numors\n",
    "# tol = 5\n",
    "# numor_list = ['46349', '56059', '54261', '69958']\n",
    "# plt.figure(figsize=(15,5))\n",
    "# for i, numor in enumerate(numor_list):\n",
    "#     viri = [plt.cm.viridis(i / len(numor_list)) for i in range(len(numor_list))]\n",
    "#     offset1r = np.load(f'/Users/cadenmyers/billingelab/dev/sym_adapted_filts/working_code/ratchet_model/data/reverse_tol_{tol}_{numor}_offsets.npz')['offset1']\n",
    "#     offset2r = np.load(f'/Users/cadenmyers/billingelab/dev/sym_adapted_filts/working_code/ratchet_model/data/reverse_tol_{tol}_{numor}_offsets.npz')['offset2']\n",
    "#     # plt.plot(-(offset1r - offset1r[0]), color=viri[i], label=f'offset1 ratchet tol={tol}')\n",
    "#     # velo2 = compute_smoothed_derivative(offset2r)\n",
    "#     # velo = compute_smoothed_derivative(offset1r)\n",
    "#     # plt.plot(velo, color=viri[i], label=f'velo {numor}')\n",
    "#     # plt.axhline(0, color='black')\n",
    "#     # plt.plot(velo2, color=viri[i]linestyle=':')\n",
    "#     # plt.plot(-(offset2r - offset2r[0]), color=viri[i], linestyle=':')\n",
    "\n",
    "# plt.grid(True)\n",
    "# plt.ylabel('angular velo deg/sec')\n",
    "# plt.xlabel('index')\n",
    "# plt.legend()\n",
    "# plt.title(f'{numor_list}, window length={window_length}, poly order={polyorder}')\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --MISC FUNCTION BELOW--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use GD to tune ratchet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "MAX_ITER_OFFSET1 = 50\n",
    "MAX_ITER_OFFSET2 = 50\n",
    "LR = 1e-2\n",
    "GD_numor = '44192'\n",
    "offset1_init = torch.tensor(0., requires_grad=True)\n",
    "offset2_init = torch.tensor(0., requires_grad=True)\n",
    "dps_seed = np.load(f'/Users/cadenmyers/billingelab/dev/sym_adapted_filts/experimental_data/npz_sept_numor_data/{numor}.npz')['data']\n",
    "\n",
    "offset1_seed_array = np.load(f'/Users/cadenmyers/billingelab/dev/sym_adapted_filts/working_code/ratchet_model/data/{GD_numor}_ratchet_offsets.npz')['offset1']\n",
    "offset2_seed_array = np.load(f'/Users/cadenmyers/billingelab/dev/sym_adapted_filts/working_code/ratchet_model/data/{GD_numor}_ratchet_offsets.npz')['offset2']\n",
    "i = 0\n",
    "offset1_seed = offset1_seed_array[i]\n",
    "offset2_seed = offset2_seed_array[i]\n",
    "\n",
    "def filter_function_torch(k, offset, n_folds=n_folds):\n",
    "    filter = torch.exp(k * torch.log((torch.cos(n_folds / 2 * (torch.tensor(DATA_THETA) + offset)))**2))\n",
    "    # print('k=', k, 'n_folds=', n_folds)\n",
    "    # plt.imshow(filter)\n",
    "    # plt.title(f'n_folds={n_folds}, k={k}')\n",
    "    # plt.show()\n",
    "    return filter\n",
    "\n",
    "def gradient_descent_optimize_seeded_offset(intensity, offset1_seed, offset2_seed):\n",
    "    '''\n",
    "    Takes in offset seeds from ratchet model and refines the offset.\n",
    "\n",
    "    all offset inputs [=] degrees\n",
    "    all offset outputs [=] degrees\n",
    "    '''\n",
    "    # initialize the offsets with the seeds from ratchet model\n",
    "    offset1 = torch.tensor(np.deg2rad(offset1_seed), dtype=torch.float32, requires_grad=True)\n",
    "    offset2 = torch.tensor(np.deg2rad(offset2_seed), dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "    opt1 = torch.optim.Adam([offset1], lr=LR)\n",
    "    opt2 = torch.optim.Adam([offset2], lr=LR)\n",
    "\n",
    "    for _ in range(MAX_ITER_OFFSET1):\n",
    "        loss = -(torch.tensor(intensity, dtype=torch.float32) * filter_function_torch(k, offset1)).sum()\n",
    "        opt1.zero_grad()\n",
    "        loss.backward()\n",
    "        opt1.step()\n",
    "\n",
    "    for _ in range(MAX_ITER_OFFSET2):\n",
    "        loss = -(torch.tensor(intensity, dtype=torch.float32) * filter_function_torch(k, offset2)).sum()\n",
    "        opt2.zero_grad()\n",
    "        loss.backward()\n",
    "        opt2.step()\n",
    "    offset1 = np.rad2deg(offset1.detach().item())\n",
    "    offset2 = np.rad2deg(offset2.detach().item())\n",
    "    return offset1, offset2\n",
    "\n",
    "# off1, off2 = gradient_descent_optimize_seeded_offset(dps[i])\n",
    "# print(offset1_seed, offset2_seed, off1, off2)\n",
    "\n",
    "refined_offset1, refined_offset2 = [], []\n",
    "\n",
    "for i, dp in enumerate(dps_seed):\n",
    "    off1, off2 = gradient_descent_optimize_seeded_offset(dp, offset1_seed_array[i], offset2_seed_array[i])\n",
    "    refined_offset1.append(off1)\n",
    "    refined_offset2.append(off2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skyrmion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
