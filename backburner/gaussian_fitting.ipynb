{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "# Load the npz file\n",
    "data = np.load('/Users/neilhazra/Downloads/pos25mT_553_50mW.npz')['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks_split(frame, params=[]):\n",
    "    x, y= np.meshgrid(np.arange(-frame.shape[0]//2, +frame.shape[0]//2), np.arange(-frame.shape[0]//2, +frame.shape[0]//2))\n",
    "    r = x**2 + y**2\n",
    "    theta = np.atan2(x,y)\n",
    "\n",
    "    thetas = np.linspace(-np.pi,np.pi, 360)\n",
    "    dtheta = thetas[1] - thetas[0]\n",
    "    theta_slices = []\n",
    "    for i, th in enumerate(thetas):\n",
    "        theta_slices.append(frame[(theta < (th + dtheta/2)) & (theta >(th - dtheta/2))].mean())\n",
    "    theta_intensity = np.nan_to_num(np.array(theta_slices))\n",
    "    n = 5\n",
    "    convolved = scipy.ndimage.convolve(theta_intensity, [1/n]*n, mode='wrap')\n",
    "    def grid_search_curve_fit(func, xdata, ydata, param_grid, prev_estimate, bounds=None):\n",
    "        param_values = list(param_grid.values())\n",
    "        \n",
    "        # Generate all combinations of initial parameters\n",
    "        from itertools import product\n",
    "        param_combinations = list(product(*param_values))\n",
    "        \n",
    "        # Initialize variables to store the best fit\n",
    "        best_params = None\n",
    "        best_covariance = None\n",
    "        best_error = np.inf\n",
    "        \n",
    "        # Loop over all parameter combinations\n",
    "        for initial_guess in param_combinations + prev_estimate:\n",
    "            try:\n",
    "                # Fit using the current set of initial parameters\n",
    "                params, covariance = curve_fit(func, xdata, ydata, p0=initial_guess)\n",
    "                \n",
    "                # Calculate the residual sum of squares (RSS)\n",
    "                residuals = ydata - func(xdata, *params)\n",
    "                rss = np.sum(residuals**2)\n",
    "                \n",
    "                # Check if this fit is better than the previous best\n",
    "                if rss < best_error:\n",
    "                    best_error = rss\n",
    "                    best_params = params\n",
    "                    best_covariance = covariance\n",
    "            \n",
    "            except RuntimeError:\n",
    "                print('not convergred')\n",
    "                # Catch the case where curve_fit fails to converge for certain parameter sets\n",
    "                pass\n",
    "        return best_params, best_covariance, best_error\n",
    "\n",
    "    # Define the function for a mixture of Gaussian peaks distributed at angles in degrees\n",
    "    def gaussian_mixture(x, w1, sigma1, theta1_start, w2, theta2_start):\n",
    "        # Convert angles to radians for computation (since Gaussians use squared distance)\n",
    "        x_rad = np.radians(x)\n",
    "        \n",
    "        # First set of 6 peaks (60 degrees apart)\n",
    "        peaks1 = [(theta1_start + i * 60) % 360 for i in range(6)]\n",
    "        \n",
    "        # Second set of 6 peaks (60 degrees apart)\n",
    "        peaks2 = [(theta2_start + i * 60) % 360 for i in range(6)]\n",
    "        \n",
    "        # Convert peak angles to radians\n",
    "        peaks1_rad = np.radians(peaks1)\n",
    "        peaks2_rad = np.radians(peaks2)\n",
    "        \n",
    "        # Gaussian contributions from the first set of peaks\n",
    "        gaussian1 = np.zeros_like(x_rad)\n",
    "        for peak in peaks1_rad:\n",
    "            gaussian1 += w1 * np.exp(-0.5 * ((x_rad - peak) / sigma1)**2) / np.sqrt(2 * np.pi * sigma1**2)\n",
    "        \n",
    "        # Gaussian contributions from the second set of peaks\n",
    "        gaussian2 = np.zeros_like(x_rad)\n",
    "        for peak in peaks2_rad:\n",
    "            gaussian2 += w2 * np.exp(-0.5 * ((x_rad - peak) / sigma1)**2) / np.sqrt(2 * np.pi * sigma1**2)\n",
    "        \n",
    "        # Total mixture of both sets of peaks\n",
    "        return gaussian1 + gaussian2 + np.mean(convolved) * 2/3\n",
    "\n",
    "    param_grid = {\n",
    "        'w1': [0.25, 0.5, 1],   # Variations around 40\n",
    "        'sigma1': [0.008, 0.01, 0.02],  # Variations around 1\n",
    "        'mu1': [np.argmax(convolved)],  # Variations around 20\n",
    "        'w2': [0.25, 0.5, 1],   # Variations around 20\n",
    "        'mu2': [np.argmax(convolved) - 15, np.argmax(convolved) - 10, np.argmax(convolved) + 10, np.argmax(convolved) + 15],  # Variations around 50\n",
    "    }\n",
    "\n",
    "    params, _, _ = grid_search_curve_fit(gaussian_mixture, np.arange(convolved.shape[0]), convolved, param_grid=param_grid, prev_estimate=params)\n",
    "    print(params)\n",
    "    w1_fit, sigma1_fit,mu1_fit, w2_fit, mu2_fit = params\n",
    "    fitted_pdf = gaussian_mixture(np.arange(convolved.shape[0]), w1_fit, sigma1_fit, mu1_fit, w2_fit, mu2_fit)\n",
    "    return mu1_fit % 60, mu2_fit % 60, fitted_pdf, convolved, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = data[250]\n",
    "frame = data[225]\n",
    "frame = data[109]\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_1, theta_2, fitted_pdf, theta_intensity, params = find_peaks_split(data[275])\n",
    "print(theta_1, theta_2)\n",
    "plt.plot(theta_intensity)\n",
    "plt.plot(fitted_pdf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_1s =  []\n",
    "theta_2s = []\n",
    "prev = None\n",
    "frames = []\n",
    "for i, frame in enumerate(data):\n",
    "    if prev is None:   \n",
    "        theta_1, theta_2, _ , _, prev = find_peaks_split(frame, [prev])\n",
    "    else:\n",
    "        theta_1, theta_2, _ , _, prev = find_peaks_split(frame)\n",
    "    theta_1s.append(theta_1)\n",
    "    theta_2s.append(theta_2)\n",
    "    frames.append(i)\n",
    "    print(i, 'out of', len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import median_filter\n",
    "\n",
    "plt.plot(frames, median_filter(theta_1s, 25), label='theta1')\n",
    "plt.plot(frames,  median_filter(theta_2s, 25), label = 'theta2')\n",
    "plt.xlabel('Frame index')\n",
    "plt.ylabel('theta_1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
