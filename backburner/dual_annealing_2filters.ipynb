{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: This will run if you have the the movies saved as \"start_numor\".npz files. Check other notebook titled SANS_to_npz.ipynb for code to assist in doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "to run the notebook, first replace all file paths (check for `np.load` and `file_path`).\n",
    "search for `gif = movies[i]` where this line allows you to change the set of data\n",
    "Parameters to tune: `FILTER_SIGNAL_THRESHOLD`, `laser_threshold`, `angle_above_offset` (in fix snapback section where you can decide if you want to change offsets)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent (2 filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageSequence\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters (don't change)\n",
    "MS = torch.arange(12)\n",
    "ANGLES = torch.arange(0, 6) * 2 * torch.pi / 6.\n",
    "\n",
    "# Extract data_theta, doesn't matter what images is extracted since we're just getting theta\n",
    "# DATA = np.load(r\"C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Angle reference file (random file from Caden)\\image_111010.npz\")['data']\n",
    "DATA = np.load('/Users/cadenmyers/billingelab/dev/skyrmion_lattices/experimental_data/npz_temp_sweep/image_theta.npz')['data']\n",
    "DATA_THETA = torch.atan2(torch.tensor(DATA[1]), torch.tensor(DATA[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create filter\n",
    "def project_theta(theta, m_values):\n",
    "    projections = []\n",
    "    for m in m_values:\n",
    "        sin_m_theta = torch.sin(m * theta)\n",
    "        cos_m_theta = torch.cos(m * theta)\n",
    "        projected_vectors = torch.stack((cos_m_theta, sin_m_theta), axis=-1)\n",
    "        projections.append(projected_vectors)\n",
    "    return torch.stack(projections, axis=0)\n",
    "\n",
    "def evaluate_functions_on_theta(theta, coefficients_list, m_values):\n",
    "    evaluated_function = torch.zeros(theta.shape, dtype=torch.float32)    \n",
    "    for (a_cos, a_sin), m in zip(coefficients_list, m_values):\n",
    "        evaluated_function += a_sin * torch.sin(m * theta) + a_cos * torch.cos(m * theta)\n",
    "    return evaluated_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks\n",
    "def apply_threshold_to_sin(image, threshold=-1):\n",
    "    \"\"\"Thin out the laser by creating a mask from image, setting values below `threshold` to 0.\n",
    "    Image intensities are first normalized between 0 and 1. So typically threshold is between 0 and 1. \n",
    "    ** Higher threshold means thinner lasers. **\n",
    "    When `threshold = -1` (default value) this function doesn't change anything.\n",
    "    \"\"\"\n",
    "    mask = torch.ones_like(image, dtype=torch.float32)\n",
    "    image = (image - image.min()) / (image.max() - image.min())\n",
    "    mask[image < threshold] = 0\n",
    "    masked_image = image * mask\n",
    "    return masked_image\n",
    "\n",
    "def create_mask_from_intensity(intensity, evaluate_image):\n",
    "    \"\"\"Mask regions in `evaluate_image` where the values are positive, setting these regions in `intensity` to 0.\n",
    "    This allows for a masked intensity image to be used in multiple filterings.\"\"\"\n",
    "    mask = torch.ones_like(evaluate_image, dtype=torch.float32)\n",
    "    mask[evaluate_image > 0] = 0\n",
    "    masked_intensity = intensity * mask\n",
    "    return masked_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters for model (usually we don't need to change this)\n",
    "# MAX_ITER_OFFSET = 101\n",
    "# LR = 1e-2\n",
    "OFFSET_ADJUSTMENT = 60\n",
    "FILTER_SIGNAL_THRESHOLD = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import dual_annealing\n",
    "\n",
    "# Optimization function\n",
    "def optimize_single_offset(intensity, offset, laser_threshold=-1):\n",
    "    #initial_offset = offset.item()\n",
    "    initial_offset = offset\n",
    "    bounds=[(initial_offset-15, initial_offset+15)]\n",
    "\n",
    "    # Objective function\n",
    "    def objective_function(offset):\n",
    "        projection = project_theta(ANGLES + offset, MS).sum(1)\n",
    "        evaluate_image_theta = evaluate_functions_on_theta(DATA_THETA, projection, MS)\n",
    "        evaluate_image_theta = apply_threshold_to_sin(evaluate_image_theta, threshold=laser_threshold)\n",
    "        loss = -(intensity * evaluate_image_theta).sum()\n",
    "        return loss.item()\n",
    "\n",
    "    # Perform optimization\n",
    "    result = dual_annealing(objective_function, bounds, seed=42, no_local_search=False)\n",
    "    optimal_offset = result.x[0]#torch.tensor(result.x[0], dtype=torch.float32)\n",
    "    #candidates = [optimal_offset, optimal_offset + 60, optimal_offset - 60]    \n",
    "    #closest_offset = min(candidates, key=lambda x: abs(x - initial_offset))\n",
    "    final_projection = project_theta(ANGLES + optimal_offset, MS).sum(1)\n",
    "    final_evaluate_image_theta = evaluate_functions_on_theta(DATA_THETA, final_projection, MS)\n",
    "    final_evaluate_image_theta = apply_threshold_to_sin(final_evaluate_image_theta, threshold=laser_threshold)\n",
    "    # final_loss = -(intensity * final_evaluate_image_theta).sum()\n",
    "    return optimal_offset, final_evaluate_image_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 filters\n",
    "def optimize_offset_2filters(intensity, offset1, offset2, laser_threshold=-1):\n",
    "    \"\"\"\n",
    "    Determine the additional laser as follows:\n",
    "    1. mask intensity: mask out the intensity data of the previous laser.\n",
    "    2. check for signals: if no strong signal remains, assume no additional peaks.\n",
    "       apply a filter to the original intensity to detect the same laser with potentially different offset angles.\n",
    "    3. otherwise apply filter to masked intensity.\n",
    "    \"\"\"\n",
    "    print(\"Optimizing offset 1...\")\n",
    "    offset1, evaluate_image_theta1 = optimize_single_offset(intensity, offset1, laser_threshold=laser_threshold)\n",
    "    masked_intensity = create_mask_from_intensity(intensity, evaluate_image_theta1)\n",
    "    if masked_intensity.max() <= FILTER_SIGNAL_THRESHOLD * intensity.max():\n",
    "        masked_intensity = intensity\n",
    "    \n",
    "    print('Optimizing offset 2...')\n",
    "    offset2, evaluate_image_theta2 = optimize_single_offset(masked_intensity, offset2, laser_threshold=laser_threshold)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15, 5))\n",
    "    im0 = ax[0].imshow(((evaluate_image_theta1 / evaluate_image_theta1.abs().max() + intensity / intensity.abs().max()).detach()).T, origin='lower')\n",
    "    ax[0].set_title('GD 1')\n",
    "    # fig.colorbar(im0, ax=ax[0])\n",
    "\n",
    "    im1 = ax[1].imshow(((evaluate_image_theta2 / evaluate_image_theta2.abs().max() + intensity / intensity.abs().max()).detach()).T, origin='lower')\n",
    "    ax[1].set_title('GD 2')\n",
    "    # fig.colorbar(im1, ax=ax[1])\n",
    "    \n",
    "    im2 = ax[2].imshow(intensity.T, origin='lower')\n",
    "    ax[2].set_title('Signal searched in GD 1')\n",
    "    # fig.colorbar(im2, ax=ax[2])\n",
    "\n",
    "    im3 = ax[3].imshow(masked_intensity.T, origin='lower')\n",
    "    ax[3].set_title('Signal searched in GD 2')\n",
    "   #  fig.colorbar(im3, ax=ax[3])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return offset1, offset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to fix snapback\n",
    "def adjust_offset_within_bounds(offset_list, angle_above_offset=50):\n",
    "    angle_below_offset = 60 - angle_above_offset\n",
    "    adjusted_offsets = []\n",
    "    prev_offset = offset_list[0]\n",
    "    for index, offset in enumerate(offset_list):\n",
    "        if index == 0:\n",
    "            adjusted_offsets.append(offset)\n",
    "            prev_offset = offset\n",
    "        else:\n",
    "            offset_range = (prev_offset - angle_below_offset, prev_offset + angle_above_offset)\n",
    "            while not (offset_range[0] <= offset <= offset_range[1]):\n",
    "                offset += OFFSET_ADJUSTMENT if offset < offset_range[0] else -OFFSET_ADJUSTMENT\n",
    "            adjusted_offsets.append(offset)\n",
    "            prev_offset = offset\n",
    "    return adjusted_offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply functions to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import images from .npz files\n",
    "# Extract data file paths\n",
    "# file_path = r'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\HDF to npz files\\\\'\n",
    "file_path = \"/Users/cadenmyers/billingelab/dev/skyrmion_lattices/experimental_data/npz_field_sweep_old/\"\n",
    "movies = ['Field_29mT.npz', 'Field_31mT.npz', 'Field_32mT.npz', 'Field_33mT.npz', 'Field_37mT.npz']\n",
    "\n",
    "# Define the movie you want to run GD and GS on as gif (gif = movies[i])\n",
    "gif = movies[0]\n",
    "print(gif)\n",
    "movie = np.load(file_path + gif)\n",
    "intensity_data = torch.tensor(movie['data'])\n",
    "print(intensity_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to tune\n",
    "laser_threshold = 0.94\n",
    "# you can also change angle_above_offset in the next chunk\n",
    "\n",
    "# Loop through the movie\n",
    "offset_list1, offset_list2 = [], []\n",
    "offset1 = 0#torch.tensor(0., requires_grad=True)\n",
    "offset2 = 0#torch.tensor(0., requires_grad=True)\n",
    "for index, image in enumerate(intensity_data):\n",
    "    offset1, offset2 = optimize_offset_2filters(image, offset1, offset2, laser_threshold=laser_threshold)\n",
    "    print(f'{(index + 1) * 10}s: offset 1 = {offset1}, offset 2 = {offset2}')\n",
    "    offset_list1.append(offset1), offset_list2.append(offset2)\n",
    "    #print(f'{(index + 1) * 10}s: offset 1 = {np.rad2deg(offset1.item())}, offset 2 = {np.rad2deg(offset2.item())}')\n",
    "    #offset_list1.append(np.rad2deg(offset1.item())), offset_list2.append(np.rad2deg(offset2.item()))\n",
    "\n",
    "# Plot offset angles\n",
    "time = np.array(range(len(offset_list1))) * 10 + 10\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "ax[0].plot(offset_list1, label=\"offset1\")\n",
    "ax[1].plot(offset_list2, label=\"offset2\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.show()\n",
    "\n",
    "print(offset_list1)\n",
    "print(offset_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to fix snapback\n",
    "adjusted_offset_list1 = offset_list1#adjust_offset_within_bounds(offset_list1, angle_above_offset=10)\n",
    "adjusted_offset_list2 = offset_list2#adjust_offset_within_bounds(offset_list2, angle_above_offset=20)\n",
    "\n",
    "# Plot offset angles\n",
    "time = np.array(range(len(offset_list1))) * 10 + 10\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "ax[0].plot(adjusted_offset_list1, label=\"adjusted offset1\")\n",
    "ax[1].plot(adjusted_offset_list2, label=\"adjusted offset2\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.show()\n",
    "\n",
    "# Save model data\n",
    "adjusted_offset_list1=np.array(adjusted_offset_list1)\n",
    "adjusted_offset_list2=np.array(adjusted_offset_list2)\n",
    "# file_path = r'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Peak Tracking npz files\\\\'\n",
    "file_path = rf'/Users/yucongchen/billingegroup/skyrmion_lattices/skyrmion-lattices-data/Field_Sweep_data/angles/'\n",
    "full_path = file_path + gif\n",
    "np.savez(full_path, gif, offset1=adjusted_offset_list1, offset2=adjusted_offset_list2, time=time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angular velocity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = ['Field_29mT.npz', 'Field_31mT.npz', 'Field_32mT.npz', 'Field_33mT.npz','Field_37mT.npz']\n",
    "\n",
    "for gif in movies:\n",
    "    # ratchet_model_data = np.load(rf'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Peak Tracking npz files\\{gif}')\n",
    "    ratchet_model_data = np.load(rf'/Users/yucongchen/billingegroup/skyrmion_lattices/skyrmion-lattices-data/Field_Sweep_data/angles/{gif}')\n",
    "    rm_time = ratchet_model_data['time']\n",
    "    rm_offset1 = ratchet_model_data['offset1']\n",
    "    rm_offset2 = ratchet_model_data['offset2']\n",
    "    plt.plot(rm_time, rm_offset1, label=f'{gif}, offset1', alpha=.7)\n",
    "    plt.plot(rm_time, rm_offset2, label=f'{gif}, offset2', alpha=.7)\n",
    "\n",
    "plt.xlabel('time (s)')\n",
    "# plt.xlim(0, 380)\n",
    "plt.ylabel('offset angle (deg)')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.5, 0.8))\n",
    "plt.title('Field Sweep offset angle')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(r'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Exported Figures\\FieldSweepPositions.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "def compute_smoothed_derivative(time, offset, window_length=11, polyorder=2):\n",
    "    '''compute velocity of data after savgol_filter is applied'''\n",
    "    smoothed_angle = savgol_filter(offset, window_length=window_length, polyorder=polyorder)\n",
    "    time = np.array(time)\n",
    "    smoothed_derivative = (np.gradient(smoothed_angle, time))\n",
    "    return smoothed_derivative\n",
    "\n",
    "# calculate angular velo and plot\n",
    "for gif in movies:\n",
    "    # ratchet_model_data = np.load(rf'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Peak Tracking npz files\\{gif}')\n",
    "    ratchet_model_data = np.load(rf'/Users/yucongchen/billingegroup/skyrmion_lattices/skyrmion-lattices-data/Field_Sweep_data/angles/{gif}')\n",
    "    rm_time = ratchet_model_data['time']\n",
    "    rm_offset1 = ratchet_model_data['offset1']\n",
    "    rm_offset2 = ratchet_model_data['offset2']\n",
    "    velo1 = compute_smoothed_derivative(rm_time, rm_offset1)\n",
    "    velo2 = compute_smoothed_derivative(rm_time, rm_offset2)\n",
    "    plt.plot(rm_time, velo1, label=f'{gif}, velocity1, average = {np.mean(velo1): .04f}', alpha=.7)\n",
    "    plt.plot(rm_time, velo2, label=f'{gif}, velocity2, average = {np.mean(velo2): .04f}', alpha=.7)\n",
    "\n",
    "plt.xlabel('time (s)')\n",
    "# plt.xlim(0,380)\n",
    "plt.ylabel('Angular Velocity (deg/s)')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.8, 0.8))\n",
    "# plt.title('Ratchet Model')\n",
    "plt.grid(True)\n",
    "# plt.savefig(r'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Exported Figures\\FieldSweepVelocities.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
