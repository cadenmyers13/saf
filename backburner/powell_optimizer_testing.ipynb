{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: This will run if you have the the movies saved as \"start_numor\".npz files. Check other notebook titled SANS_to_npz.ipynb for code to assist in doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "to run the notebook, first replace all file paths (check for `np.load` and `file_path`).\n",
    "search for `gif = movies[i]` where this line allows you to change the set of data\n",
    "Parameters to tune: `FILTER_SIGNAL_THRESHOLD`, `laser_threshold`, `angle_above_offset` (in fix snapback section where you can decide if you want to change offsets)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Powell optimizer (2 filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters (don't change)\n",
    "MS = torch.arange(12)\n",
    "ANGLES = torch.arange(0, 6) * 2 * torch.pi / 6.\n",
    "\n",
    "# Extract data_theta, doesn't matter what images is extracted since we're just getting theta\n",
    "# DATA = np.load(r\"C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Angle reference file (random file from Caden)\\image_111010.npz\")['data']\n",
    "DATA = np.load('/Users/cadenmyers/billingelab/dev/skyrmion_lattices/experimental_data/npz_temp_sweep/image_theta.npz')['data']\n",
    "DATA_THETA = torch.atan2(torch.tensor(DATA[1]), torch.tensor(DATA[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_min_max(data):\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        array = data.numpy()\n",
    "    else:\n",
    "        array = data\n",
    "\n",
    "    array_min = np.min(array)\n",
    "    array_max = np.max(array)\n",
    "    norm_array = (array - array_min) / (array_max - array_min)\n",
    "\n",
    "    if isinstance(data, torch.Tensor):\n",
    "        norm_tensor = torch.tensor(norm_array)\n",
    "        return norm_tensor\n",
    "    else:\n",
    "        return norm_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create masks\n",
    "def apply_threshold_to_sin(filter, threshold=.5):\n",
    "    \"\"\"Given threshold value between 0 and 1, this function sets all values below threshold to 0 and \n",
    "    everything above threshold to 1. Input images are first normalized between 0 and 1. \n",
    "    So typically threshold is between 0 and 1. \n",
    "    ** Higher threshold means thinner lasers. **\n",
    "    When `threshold = -1` (default value) this function doesn't change anything.\n",
    "    \"\"\"\n",
    "    mask = torch.ones_like(filter, dtype=torch.float32)\n",
    "    filter = normalize_min_max(filter)\n",
    "    mask[filter < threshold] = 0\n",
    "    mask[filter >= threshold] = 1\n",
    "    mask_with_applied_threshold = mask\n",
    "    return mask_with_applied_threshold\n",
    "\n",
    "\n",
    "def create_mask_from_intensity(intensity, evaluate_image):\n",
    "    \"\"\"Mask regions in `evaluate_image` where the values are positive, setting these regions in `intensity` to 0.\n",
    "    This allows for a masked intensity image to be used in multiple filterings.\"\"\"\n",
    "    mask = torch.ones_like(evaluate_image, dtype=torch.float32)\n",
    "    mask[evaluate_image > 0] = 0\n",
    "    masked_intensity = intensity * mask\n",
    "    return masked_intensity\n",
    "\n",
    "### VISUALIZE EFFECTS OF apply_threshold_to_sin() FUNCTION ###\n",
    "# projection = project_theta(ANGLES, MS).sum(1)\n",
    "# evaluate_image_theta = evaluate_functions_on_theta(DATA_THETA, projection, MS)\n",
    "# mask = apply_threshold_to_sin(evaluate_image_theta)\n",
    "# plt.imshow(mask)\n",
    "\n",
    "### MISC STUFF ###\n",
    "# projection = project_theta(ANGLES, MS).sum(1)\n",
    "# evaluate_image_theta = evaluate_functions_on_theta(DATA_THETA, projection, MS)\n",
    "# step_func_mask = apply_threshold_to_sin(evaluate_image_theta)\n",
    "# plt.imshow(step_func_mask)\n",
    "# plt.show()\n",
    "# masked_image = create_mask_from_intensity(intensity_data[0], step_func_mask)\n",
    "# plt.imshow(masked_image)\n",
    "# plt.show()\n",
    "# plt.imshow(intensity_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters for model (usually we don't need to change this)\n",
    "# MAX_ITER_OFFSET = 101\n",
    "# LR = 1e-2\n",
    "OFFSET_ADJUSTMENT = np.deg2rad(60)\n",
    "FILTER_SIGNAL_THRESHOLD = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINING FILTER\n",
    "\n",
    "def exp_ln_filter(offset, DATA_THETA, k):\n",
    "    filter = torch.exp( k * torch.log( (torch.sin(3 * (DATA_THETA + offset)))**2 ) )\n",
    "    return filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POWELL OPTIMIZER\n",
    "k = 1\n",
    "\n",
    "def optimize_single_offset(intensity, offset):\n",
    "    initial_offset = offset\n",
    "    bounds=[(np.deg2rad(initial_offset-25), np.deg2rad(initial_offset+25))]\n",
    "\n",
    "    def objective_function(offset):\n",
    "        evaluate_image_theta = exp_ln_filter(offset, DATA_THETA=DATA_THETA, k=k)\n",
    "        loss = -(intensity * evaluate_image_theta).sum()\n",
    "        return loss.item()\n",
    "\n",
    "    result = minimize(objective_function, [initial_offset], method='Powell', bounds=bounds)\n",
    "    optimal_offset = result.x[0]\n",
    "\n",
    "    final_evaluate_image_theta = exp_ln_filter(optimal_offset, DATA_THETA=DATA_THETA, k=k)\n",
    "\n",
    "    return optimal_offset, final_evaluate_image_theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 filters\n",
    "def optimize_offset_2filters(intensity, offset1, offset2, laser_threshold=-1):\n",
    "    \"\"\"\n",
    "    Determine the additional laser as follows:\n",
    "    1. mask intensity: mask out the intensity data of the previous laser.\n",
    "    2. check for signals: if no strong signal remains, assume no additional peaks.\n",
    "       apply a filter to the original intensity to detect the same laser with potentially different offset angles.\n",
    "    3. otherwise apply filter to masked intensity.\n",
    "    \"\"\"\n",
    "    print(\"Optimizing offset 1...\")\n",
    "    offset1, evaluate_image_theta1 = optimize_single_offset(intensity, offset1, laser_threshold=laser_threshold)\n",
    "    masked_intensity = create_mask_from_intensity(intensity, evaluate_image_theta1)\n",
    "    if masked_intensity.max() <= FILTER_SIGNAL_THRESHOLD * intensity.max():\n",
    "        masked_intensity = intensity\n",
    "    \n",
    "    print('Optimizing offset 2...')\n",
    "    offset2, evaluate_image_theta2 = optimize_single_offset(masked_intensity, offset2, laser_threshold=laser_threshold)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15, 5))\n",
    "    im0 = ax[0].imshow(((evaluate_image_theta1 / evaluate_image_theta1.abs().max() + intensity / intensity.abs().max()).detach()).T, origin='lower')\n",
    "    ax[0].set_title('GD 1')\n",
    "    # fig.colorbar(im0, ax=ax[0])\n",
    "\n",
    "    im1 = ax[1].imshow(((evaluate_image_theta2 / evaluate_image_theta2.abs().max() + intensity / intensity.abs().max()).detach()).T, origin='lower')\n",
    "    ax[1].set_title('GD 2')\n",
    "    # fig.colorbar(im1, ax=ax[1])\n",
    "    \n",
    "    im2 = ax[2].imshow(intensity.T, origin='lower')\n",
    "    ax[2].set_title('Signal searched in GD 1')\n",
    "    # fig.colorbar(im2, ax=ax[2])\n",
    "\n",
    "    im3 = ax[3].imshow(masked_intensity.T, origin='lower')\n",
    "    ax[3].set_title('Signal searched in GD 2')\n",
    "   #  fig.colorbar(im3, ax=ax[3])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return np.rad2deg(offset1), np.rad2deg(offset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_split_logic(offset1, offset2, offset_diff_threshold=1):\n",
    "    '''Determines if there is peak splitting based off input threshold value'''\n",
    "    offset_diff_threshold = np.deg2rad(offset_diff_threshold)\n",
    "    offset2_valid = True\n",
    "    if np.abs(offset1 - offset2) <= offset_diff_threshold:\n",
    "        offset2_valid = False\n",
    "\n",
    "    offset2_val = np.nan if not offset2_valid else offset2\n",
    "    return offset2_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCORPORATING LOGIC\n",
    "\n",
    "def optimize_offset_2filters(intensity, offset1, offset2, laser_threshold=-1):\n",
    "    \"\"\"\n",
    "    Determine the additional laser as follows:\n",
    "    1. mask intensity: mask out the intensity data of the previous laser.\n",
    "    2. check for signals: if no strong signal remains, assume no additional peaks.\n",
    "       apply a filter to the original intensity to detect the same laser with potentially different offset angles.\n",
    "    3. otherwise apply filter to masked intensity.\n",
    "    \"\"\"\n",
    "    print(\"Optimizing offset 1...\")\n",
    "    offset1, evaluate_image_theta1 = optimize_single_offset(intensity, offset1, laser_threshold=laser_threshold)\n",
    "    masked_intensity = create_mask_from_intensity(intensity, evaluate_image_theta1)\n",
    "    if masked_intensity.max() <= FILTER_SIGNAL_THRESHOLD * intensity.max():\n",
    "        masked_intensity = intensity\n",
    "    \n",
    "    print('Optimizing offset 2...')\n",
    "    offset2, evaluate_image_theta2 = optimize_single_offset(masked_intensity, offset2, laser_threshold=laser_threshold)\n",
    "    \n",
    "    # offset2 = peak_split_logic(offset1, offset2)\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(15, 5))\n",
    "    im0 = ax[0].imshow(((evaluate_image_theta1 / evaluate_image_theta1.abs().max() + intensity / intensity.abs().max()).detach()).T, origin='lower')\n",
    "    ax[0].set_title('Powell 1')\n",
    "    # fig.colorbar(im0, ax=ax[0])\n",
    "\n",
    "    im1 = ax[1].imshow(((evaluate_image_theta2 / evaluate_image_theta2.abs().max() + intensity / intensity.abs().max()).detach()).T, origin='lower')\n",
    "    ax[1].set_title('Powell 2')\n",
    "    # fig.colorbar(im1, ax=ax[1])\n",
    "    \n",
    "    im2 = ax[2].imshow(intensity.T, origin='lower')\n",
    "    ax[2].set_title('Signal searched in Powell 1')\n",
    "    # fig.colorbar(im2, ax=ax[2])\n",
    "\n",
    "    im3 = ax[3].imshow(masked_intensity.T, origin='lower')\n",
    "    ax[3].set_title('Signal searched in Powell 2')\n",
    "   #  fig.colorbar(im3, ax=ax[3])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return np.rad2deg(offset1), np.rad2deg(offset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to fix snapback\n",
    "def adjust_offset_within_bounds(offset_list, angle_above_offset=50):\n",
    "    angle_above_offset = np.deg2rad(angle_above_offset)\n",
    "    angle_below_offset = np.deg2rad(60) - angle_above_offset\n",
    "    adjusted_offsets = []\n",
    "    prev_offset = offset_list[0]\n",
    "    for index, offset in enumerate(offset_list):\n",
    "        if index == 0:\n",
    "            adjusted_offsets.append(offset)\n",
    "            prev_offset = offset\n",
    "        else:\n",
    "            offset_range = (prev_offset - angle_below_offset, prev_offset + angle_above_offset)\n",
    "            while not (offset_range[0] <= offset <= offset_range[1]):\n",
    "                offset += OFFSET_ADJUSTMENT if offset < offset_range[0] else -OFFSET_ADJUSTMENT\n",
    "            adjusted_offsets.append(offset)\n",
    "            prev_offset = offset\n",
    "    return adjusted_offsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply functions to real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import images from .npz files\n",
    "# Extract data file paths\n",
    "# file_path = r'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\HDF to npz files\\\\'\n",
    "file_path = \"/Users/cadenmyers/billingelab/dev/skyrmion_lattices/experimental_data/\"\n",
    "\n",
    "# FIELD SWEEP MOVIES\n",
    "filenames = ['Field_29mT.npz', 'Field_31mT.npz', 'Field_32mT.npz', 'Field_33mT.npz', 'Field_37mT.npz']\n",
    "movies = ['npz_field_sweep_old/' + filename for filename in filenames]\n",
    "\n",
    "# TEMP SWEEP MOVIES\n",
    "# filenames = ['121855.npz', '118923.npz', '119486.npz', '119996.npz', '120506.npz', '121016.npz', '121405.npz', '121550.npz', '122365.npz', '122875.npz']\n",
    "# movies = ['npz_temp_sweep/' + filename for filename in filenames]\n",
    "\n",
    "# Define the movie you want to run GD and GS on as gif (gif = movies[i])\n",
    "gif = movies[0]\n",
    "print(gif)\n",
    "movie = np.load(file_path + gif)\n",
    "intensity_data = torch.tensor(movie['data'])\n",
    "print(intensity_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to tune\n",
    "laser_threshold = 0.94\n",
    "# you can also change angle_above_offset in the next chunk\n",
    "\n",
    "# GD training data\n",
    "td_offset = np.load('/Users/cadenmyers/billingelab/dev/skyrmion_lattices/analysis-generated_data/gradient_offset_data/gradient_decent_121855.npz')['offset']\n",
    "td_time = np.load('/Users/cadenmyers/billingelab/dev/skyrmion_lattices/analysis-generated_data/gradient_offset_data/gradient_decent_121855.npz')['time']\n",
    "\n",
    "# Loop through the movie\n",
    "offset_list1, offset_list2 = [], []\n",
    "offset1 = 0#torch.tensor(0., requires_grad=True)\n",
    "offset2 = 0#torch.tensor(0., requires_grad=True)\n",
    "for index, image in enumerate(intensity_data):\n",
    "    offset1, offset2 = optimize_offset_2filters(image, offset1, offset2, laser_threshold=laser_threshold)\n",
    "\n",
    "    print(f'{(index + 1) * 10}s: offset 1 = {offset1}')\n",
    "    offset_list1.append(offset1)\n",
    "    print(f'{(index + 1) * 10}s: offset 2 = {offset2}')\n",
    "    offset_list2.append(offset2)\n",
    "\n",
    "# Plot offset angles\n",
    "time = np.array(range(len(offset_list1))) * 10 + 10\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "ax[0].plot(time, offset_list1, label=\"offset1\")\n",
    "# ax[0].plot(td_time, td_offset, label=\"td_offset\", linestyle='--')\n",
    "ax[0].set_ylabel('Offset angle')\n",
    "ax[0].set_xlabel(\"Time (s)\")\n",
    "ax[1].plot(time, offset_list2, label=\"offset2\")\n",
    "ax[1].set_ylabel('Offset angle')\n",
    "ax[1].set_xlabel(\"Time (s)\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.show()\n",
    "\n",
    "print(offset_list1)\n",
    "print(offset_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to fix snapback\n",
    "adjusted_offset_list1 = offset_list1#adjust_offset_within_bounds(offset_list1, angle_above_offset=10)\n",
    "adjusted_offset_list2 = offset_list2#adjust_offset_within_bounds(offset_list2, angle_above_offset=20)\n",
    "\n",
    "# Plot offset angles\n",
    "time = np.array(range(len(offset_list1))) * 10 + 10\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "ax[0].plot(adjusted_offset_list1, label=\"adjusted offset1\")\n",
    "ax[1].plot(adjusted_offset_list2, label=\"adjusted offset2\")\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.show()\n",
    "\n",
    "# Save model data\n",
    "adjusted_offset_list1=np.array(adjusted_offset_list1)\n",
    "adjusted_offset_list2=np.array(adjusted_offset_list2)\n",
    "# file_path = r'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Peak Tracking npz files\\\\'\n",
    "file_path = rf'/Users/yucongchen/billingegroup/skyrmion_lattices/skyrmion-lattices-data/Field_Sweep_data/angles/'\n",
    "full_path = file_path + gif\n",
    "np.savez(full_path, gif, offset1=adjusted_offset_list1, offset2=adjusted_offset_list2, time=time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angular velocity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = ['Field_29mT.npz', 'Field_31mT.npz', 'Field_32mT.npz', 'Field_33mT.npz','Field_37mT.npz']\n",
    "\n",
    "for gif in movies:\n",
    "    # ratchet_model_data = np.load(rf'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Peak Tracking npz files\\{gif}')\n",
    "    ratchet_model_data = np.load(rf'/Users/yucongchen/billingegroup/skyrmion_lattices/skyrmion-lattices-data/Field_Sweep_data/angles/{gif}')\n",
    "    rm_time = ratchet_model_data['time']\n",
    "    rm_offset1 = ratchet_model_data['offset1']\n",
    "    rm_offset2 = ratchet_model_data['offset2']\n",
    "    plt.plot(rm_time, rm_offset1, label=f'{gif}, offset1', alpha=.7)\n",
    "    plt.plot(rm_time, rm_offset2, label=f'{gif}, offset2', alpha=.7)\n",
    "\n",
    "plt.xlabel('time (s)')\n",
    "# plt.xlim(0, 380)\n",
    "plt.ylabel('offset angle (deg)')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.5, 0.8))\n",
    "plt.title('Field Sweep offset angle')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(r'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Exported Figures\\FieldSweepPositions.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "def compute_smoothed_derivative(time, offset, window_length=11, polyorder=2):\n",
    "    '''compute velocity of data after savgol_filter is applied'''\n",
    "    smoothed_angle = savgol_filter(offset, window_length=window_length, polyorder=polyorder)\n",
    "    time = np.array(time)\n",
    "    smoothed_derivative = (np.gradient(smoothed_angle, time))\n",
    "    return smoothed_derivative\n",
    "\n",
    "# calculate angular velo and plot\n",
    "for gif in movies:\n",
    "    # ratchet_model_data = np.load(rf'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Peak Tracking npz files\\{gif}')\n",
    "    ratchet_model_data = np.load(rf'/Users/yucongchen/billingegroup/skyrmion_lattices/skyrmion-lattices-data/Field_Sweep_data/angles/{gif}')\n",
    "    rm_time = ratchet_model_data['time']\n",
    "    rm_offset1 = ratchet_model_data['offset1']\n",
    "    rm_offset2 = ratchet_model_data['offset2']\n",
    "    velo1 = compute_smoothed_derivative(rm_time, rm_offset1)\n",
    "    velo2 = compute_smoothed_derivative(rm_time, rm_offset2)\n",
    "    plt.plot(rm_time, velo1, label=f'{gif}, velocity1, average = {np.mean(velo1): .04f}', alpha=.7)\n",
    "    plt.plot(rm_time, velo2, label=f'{gif}, velocity2, average = {np.mean(velo2): .04f}', alpha=.7)\n",
    "\n",
    "plt.xlabel('time (s)')\n",
    "# plt.xlim(0,380)\n",
    "plt.ylabel('Angular Velocity (deg/s)')\n",
    "plt.legend(loc='upper right', bbox_to_anchor=(1.8, 0.8))\n",
    "# plt.title('Ratchet Model')\n",
    "plt.grid(True)\n",
    "# plt.savefig(r'C:\\Users\\Nathan\\OneDrive - nd.edu\\Desktop\\SANS Data\\Experiments\\PSI Cu2OSeO3 Corbino July 2023\\Analysis\\Field Sweep\\Exported Figures\\FieldSweepVelocities.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
