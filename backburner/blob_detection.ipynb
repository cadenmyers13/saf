{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fftshift, fft2, ifft2\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage import exposure\n",
    "import torch\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import images from .npz files\n",
    "# Extract data file paths\n",
    "file_path = \"/Users/cadenmyers/billingelab/dev/skyrmion_lattices/experimental_data/npz_sept_data/npz_field_sweep/\"\n",
    "\n",
    "# TEMP SWEEP MOVIES\n",
    "# movies = ['121855.npz', '118923.npz', '119486.npz', '119996.npz', '120506.npz', '121016.npz', '121405.npz', '121550.npz', '122365.npz', '122875.npz']\n",
    "\n",
    "# FIELD SWEEP MOVIES OLD\n",
    "#movies = ['Field_29mT.npz', 'Field_31mT.npz', 'Field_32mT.npz', 'Field_33mT.npz', 'Field_37mT.npz']\n",
    "\n",
    "#SEPT DATA\n",
    "# negative [0-12]\n",
    "movies = ['neg23mT_553_50mW.npz', 'neg23mT_558_25mW.npz', 'neg25mT_553_50mW.npz', 'neg25mT_558_25mW.npz', 'neg27mT_553_50mW.npz',\n",
    "          'neg27mT_558_25mW.npz', 'neg29mT_553_50mW.npz', 'neg29mT_558_25mW.npz', 'neg31mT_553_50mW.npz', 'neg31mT_558_25mW.npz',\n",
    "          'neg33mT_553_50mW.npz', 'neg33mT_558_25mW.npz', 'neg35mT_553_50mW.npz',\n",
    "# positive [13-24]\n",
    "          'pos23mT_553_50mW.npz', 'pos23mT_558_25mW.npz', 'pos25mT_553_50mW.npz', 'pos25mT_558_25mW.npz', 'pos27mT_553_50mW.npz',\n",
    "          'pos27mT_558_25mW.npz', 'pos29mT_553_50mW.npz', 'pos29mT_558_25mW.npz', 'pos31mT_553_50mW.npz', 'pos31mT_558_25mW.npz',\n",
    "          'pos33mT_553_50mW.npz', 'pos33mT_558_25mW.npz']\n",
    "\n",
    "# Define the movie you want to run GD and GS on as gif (gif = movies[i])\n",
    "#movies = ['pos29mT_558_50mW.npz']\n",
    "gif = movies[24]\n",
    "print(gif)\n",
    "\n",
    "movie = np.load(file_path + gif)\n",
    "intensity_data = movie['data']\n",
    "# Parameters:\n",
    "#   iterations: Number of iterations to run the diffusion process.\n",
    "#   kappa: Threshold for edge stopping (higher means less edge detection).\n",
    "#   gamma: Step size (controls diffusion speed).\n",
    "niter=50\n",
    "kappa=30\n",
    "gamma=.1\n",
    "# intensity_data = torch.tensor(anisotropic_diffusion(intensity_data, niter=niter, kappa=kappa, gamma=gamma))\n",
    "print('Tensor shape should be (X,128,128), where X is the number of images.')\n",
    "print(intensity_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "\n",
    "# Extract data_theta, doesn't matter what image is extracted since we're just getting theta\n",
    "DATA = np.load('/Users/cadenmyers/billingelab/dev/skyrmion_lattices/experimental_data/npz_temp_sweep/image_theta.npz')['data']\n",
    "# DATA = np.load('/Users/yucongchen/billingegroup/skyrmion_lattices/skyrmion-lattices-data/image_111001.npz')['data']\n",
    "DATA_THETA = torch.atan2(torch.tensor(DATA[1]), torch.tensor(DATA[0]))\n",
    "resolution = 10.8 #degrees\n",
    "offset1 = torch.tensor(0., requires_grad=True)\n",
    "offset2 = torch.tensor(0., requires_grad=True)\n",
    "end_frame = len(intensity_data)\n",
    "print(end_frame)\n",
    "# for the model\n",
    "MAX_ITER_OFFSET = 101\n",
    "LR = 1e-2\n",
    "OFFSET_ADJUSTMENT = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_images(image, inner_radius=17, outer_radius=30, center_x=64, center_y=62):\n",
    "    '''Masks signal inside inner_radius and outside outer_radius around the specified center.'''\n",
    "    x, y = np.meshgrid(np.arange(image.shape[1]), np.arange(image.shape[0]))\n",
    "    radius = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)\n",
    "    mask = (radius > inner_radius) & (radius < outer_radius)\n",
    "    masked_image = np.copy(image)\n",
    "    masked_image[~mask] = 0  \n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KMeans clustering\n",
    "\n",
    "def fourier_hexagonal_clustering(image, n_clusters=2, outer_radius_filter=19, inner_radius_filter=3):\n",
    "    \"\"\"\n",
    "    Extracts hexagonal patterns from a noisy image by filtering in Fourier space \n",
    "    and applying clustering to the filtered spatial domain image.\n",
    "    \n",
    "    Parameters:\n",
    "    - image: 2D numpy array, the image to analyze.\n",
    "    - n_clusters: int, the number of clusters to separate the hexagonal patterns.\n",
    "    \n",
    "    Returns:\n",
    "    - clustered_image: Display of clustered regions in the filtered image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Fourier Transform\n",
    "    f_transform = fftshift(fft2(image))\n",
    "    magnitude_spectrum = np.log(np.abs(f_transform) + 1)\n",
    "\n",
    "    # Step 2: Apply a Circular Bandpass Filter to Enhance Hexagonal Patterns\n",
    "    # Define center and radius range for bandpass (tweak based on image)\n",
    "    center = np.array(f_transform.shape) // 2\n",
    "    y, x = np.ogrid[:f_transform.shape[0], :f_transform.shape[1]]\n",
    "    mask = ((x - center[1])**2 + (y - center[0])**2 <= outer_radius_filter**2) & \\\n",
    "           ((x - center[1])**2 + (y - center[0])**2 >= inner_radius_filter**2)\n",
    "    \n",
    "    # Apply mask to zero out other frequencies\n",
    "    f_transform_filtered = f_transform * mask\n",
    "    image_filtered = np.abs(ifft2(fftshift(f_transform_filtered)))\n",
    "    filtered_image = mask_images(image_filtered)\n",
    "    # plt.imshow(filtered_image)\n",
    "    # plt.show()\n",
    "    # Step 3: Rescale intensity for clearer clustering results\n",
    "    filtered_image = exposure.rescale_intensity(filtered_image)\n",
    "    \n",
    "    # Step 4: Flatten image and apply K-means clustering to filtered data\n",
    "    reshaped_data = filtered_image.reshape(-1, 1)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(reshaped_data)\n",
    "    labels = kmeans.labels_.reshape(filtered_image.shape)\n",
    "    \n",
    "    # Step 5: Plot the clustered regions in the filtered image\n",
    "    # plt.figure(figsize=(12, 6))\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.title(\"intensity\")\n",
    "    # plt.imshow(image)\n",
    "    \n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.title(\"Clustered Regions in Filtered Image\")\n",
    "    # plt.imshow(labels)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "    return labels\n",
    "\n",
    "print(intensity_data[0].shape)\n",
    "labels = fourier_hexagonal_clustering(intensity_data[0])\n",
    "print(labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_data = []\n",
    "for i in range(end_frame):\n",
    "    cluster = fourier_hexagonal_clustering(intensity_data[i])\n",
    "    clustered_data.append(cluster)\n",
    "\n",
    "clustered_data = np.array(clustered_data).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATION OF K-MEANS FILTERS TO APPLY TO RAW DATA\n",
    "kmeans_filter = [fourier_hexagonal_clustering(intensity_data[i]) for i in range(end_frame)]\n",
    "filtered_data = [kmeans_filter[i] * intensity_data[i] for i in range(end_frame)]\n",
    "filtered_data = np.array(filtered_data).astype('uint8')\n",
    "print(filtered_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPARSE OPTICAL FLOW\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "prev_pts = cv2.goodFeaturesToTrack(filtered_data[0], mask=None, **dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7))\n",
    "\n",
    "for i in range(1, len(filtered_data)):\n",
    "    # Compute optical flow from previous to current frame\n",
    "    next_pts, status, err = cv2.calcOpticalFlowPyrLK(filtered_data[i-1], filtered_data[i], prev_pts, None, **lk_params)\n",
    "\n",
    "    # Select the good points\n",
    "    good_new = next_pts[status == 1]\n",
    "    good_old = prev_pts[status == 1]\n",
    "\n",
    "    # Visualize optical flow\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(filtered_data[i], cmap='gray')\n",
    "    for new, old in zip(good_new, good_old):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        plt.arrow(c, d, a - c, b - d, color='r', head_width=2, head_length=4)\n",
    "    plt.title(f\"Optical Flow - Frame {i}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Update previous points for the next frame\n",
    "    prev_pts = good_new.reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DENSE OPTICAL FLOW\n",
    "\n",
    "step=4\n",
    "# Loop through the frames to calculate and plot optical flow\n",
    "for i in range(1, end_frame - 1):\n",
    "    # Calculate optical flow between consecutive frames\n",
    "    flow = cv2.calcOpticalFlowFarneback(filtered_data[i - 1], filtered_data[i], None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # Get the horizontal and vertical flow components\n",
    "    flow_x = flow[..., 0]\n",
    "    flow_y = flow[..., 1]\n",
    "\n",
    "    # Set up a grid for quiver plot with step size\n",
    "    x, y = np.meshgrid(np.arange(0, flow.shape[1], step), np.arange(0, flow.shape[0], step))\n",
    "    u = flow_y[::step, ::step]  # Vertical component\n",
    "    v = flow_x[::step, ::step]  # Horizontal component\n",
    "\n",
    "    # Plot the frame with optical flow vectors\n",
    "    # plt.figure(figsize=(8, 8))\n",
    "    # plt.imshow(filtered_data[i], cmap='gray')\n",
    "    # plt.quiver(x, y, v, u, color='red', angles='xy', scale_units='xy', scale=1)\n",
    "    # plt.title(f'Optical Flow Vectors - Frame {i}')\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 FILTER GRADIENT DESCENT\n",
    "\n",
    "def k_val(fwhm):\n",
    "    '''fwhm is your resolution given in degrees.\n",
    "\n",
    "    This is derived based off the assumption that FWHM for the cosine \n",
    "    is approximately equal to a gaussian, which is a good assumption for this case\n",
    "    Because FWHM for the cosine filter is approx equal to FWHM for a gaussian'''\n",
    "    fwhm = np.deg2rad(fwhm)\n",
    "    k = np.log(1/2) / (np.log(np.cos(3/2*fwhm)**2))\n",
    "    return k\n",
    "\n",
    "k = k_val(resolution)\n",
    "print('k =', k)\n",
    "\n",
    "n_folds = 6\n",
    "def filter_function(k, theta, n_folds=n_folds):\n",
    "    filter = torch.exp(k * torch.log((torch.cos(n_folds / 2 * theta))**2))\n",
    "    return filter\n",
    "\n",
    "offset1_init = torch.tensor(0., requires_grad=True)\n",
    "offset2_init = torch.tensor(0., requires_grad=True)\n",
    "penalty_strength = 10E6\n",
    "def gradient_descent_optimize_offset(intensity, offset, offset_second, k=k, penalty_strength=penalty_strength):\n",
    "    # First Gradient Descent to find the global maximum\n",
    "    opt = torch.optim.Adam([offset], lr=LR)\n",
    "    for i in range(MAX_ITER_OFFSET):\n",
    "        evaluate_image_theta = filter_function(k, DATA_THETA + offset)\n",
    "        loss = -(torch.tensor(intensity) * evaluate_image_theta).sum()\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # Store the first optimal offset\n",
    "    first_offset = offset.clone().detach()\n",
    "\n",
    "    # Second Gradient Descent with penalty to avoid first peak\n",
    "    opt_second = torch.optim.Adam([offset_second], lr=LR)\n",
    "    for i in range(MAX_ITER_OFFSET):\n",
    "        evaluate_image_theta_second = filter_function(k, DATA_THETA + offset_second)\n",
    "        penalty = penalty_strength * filter_function(1/2*k, offset_second - first_offset)\n",
    "\n",
    "        # Modified loss with penalty\n",
    "        loss_second = -(torch.tensor(intensity) * evaluate_image_theta_second).sum() + penalty\n",
    "        opt_second.zero_grad()\n",
    "        loss_second.backward()\n",
    "        opt_second.step()\n",
    "\n",
    "        # set all values greater that .01 to 1 in filter\n",
    "    filter_to_ones1 = evaluate_image_theta.clone().detach().numpy()\n",
    "    filter_to_ones2 = evaluate_image_theta_second.clone().detach().numpy()\n",
    "    threshold = .2\n",
    "    filter_to_ones1[filter_to_ones1 > threshold] = 1\n",
    "    filter_to_ones1[filter_to_ones1 <= threshold] = 0\n",
    "    filter_to_ones2[filter_to_ones2 > threshold] = 1\n",
    "    filter_to_ones2[filter_to_ones2 <= threshold] = 0\n",
    "\n",
    "    return first_offset.item(), filter_to_ones1, offset_second.item(), filter_to_ones2\n",
    "\n",
    "i = 5\n",
    "offset1, filter1, offset2, filter2 = gradient_descent_optimize_offset(filtered_data[i], offset1_init, offset2_init)\n",
    "# plt.imshow(filtered_data[i])\n",
    "# plt.show()\n",
    "# plt.imshow(filter1)\n",
    "# plt.show()\n",
    "# plt.imshow(filter2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(end_frame):\n",
    "    offset1, filter1, offset2, filter2 = gradient_descent_optimize_offset(filtered_data[i], offset1_init, offset2_init)\n",
    "    ones_filtered_data = intensity_data[i] * filter1 + intensity_data[i] * filter2\n",
    "    kcluster = fourier_hexagonal_clustering(ones_filtered_data)\n",
    "    plt.imshow(kcluster)\n",
    "    # plt.imshow(intensity_data[i] * filter2)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skyrmion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
